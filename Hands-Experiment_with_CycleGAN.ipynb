{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "b207aa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use STB dataset\n",
    "# Create metrics\n",
    "# Add argument parser - Munch\n",
    "# Only the ht_p2 can be made trainable after CycleGan is trained. Depth -> Generator to RGB -> Decoder (ht_p2)\n",
    "# and show performance. Thus transfer of information due to pre trained rgb weights.\n",
    "# Thus having a well trained rgb model can be used for depth based prediction correction and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "3e28cff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchgan\n",
    "import random\n",
    "import torch\n",
    "import glob, os\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torchinfo\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import PIL.Image as Image\n",
    "import pickle\n",
    "import cv2\n",
    "import imageio\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "29d217c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from AWR.model.hourglass import PoseNet\n",
    "from AWR.dataloader.nyu_loader import NYU\n",
    "from AWR.config import opt\n",
    "from AWR.util.feature_tool import FeatureModule\n",
    "from AWR.util.vis_tool import VisualUtil\n",
    "from util import dotdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "17a2012f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/debabratamandal/Jun-Dec 2021/rnd/exp/HandTailor\n"
     ]
    }
   ],
   "source": [
    "from HandTailor.demo import *\n",
    "# from HandTailor.demo_in_the_wild import *\n",
    "from jax import grad, jit, vmap\n",
    "from jax.experimental import optimizers\n",
    "import jax.numpy as npj\n",
    "from HandTailor.model import Hand2D, BottleneckBlock, HandNet\n",
    "from HandTailor.demo_in_the_wild import residuals, mano_layer\n",
    "from munch import Munch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "da82151c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchgan.losses import least_squares_generator_loss, least_squares_discriminator_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "dc92be97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "53cc1d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available() and not args.no_cuda\n",
    "device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "manualSeed = 1\n",
    "random.seed(manualSeed)\n",
    "np.random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "if use_cuda:\n",
    "  torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "SHUFFLE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "a691f3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10\n",
    "EPOCHS = 500\n",
    "NUM_WORKERS = 4\n",
    "if use_cuda:\n",
    "    PIN_MEMORY = True\n",
    "else:\n",
    "    PIN_MEMORY = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "525ad422",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARGS = Munch({'HandTailor': \n",
    "                  {'wild':True}\n",
    "             })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "4f018112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from /Users/debabratamandal/Jun-Dec 2021/rnd/exp/AWR/results/hourglass_1.pth\n",
      "loading model from /Users/debabratamandal/Jun-Dec 2021/rnd/exp/AWR/results/hourglass_1.pth\n"
     ]
    }
   ],
   "source": [
    "class AwrEncoder(nn.Module):\n",
    "    def __init__(self, opt):\n",
    "        super(AwrEncoder, self).__init__()\n",
    "        self.config = opt\n",
    "        self.stacks = int(self.config.net.split('_')[1])\n",
    "        self.net = PoseNet(self.config.net, self.config.jt_num)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        print('loading model from %s' % self.config.load_model)\n",
    "        pth = torch.load(self.config.load_model, map_location=torch.device('cpu'))\n",
    "        self.net.load_state_dict(pth['model'])\n",
    "        \n",
    "    def make_trainable(self):\n",
    "        for idx, param in enumerate(self.net.parameters()):\n",
    "            l = len(list(self.net.parameters()))\n",
    "            if idx != l-2 and idx != l-4:\n",
    "                param.requires_grad = False\n",
    "            else:\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(self, img, jt_xyz_gt, jt_uvd_gt, center_xyz, M, cube):\n",
    "        return self.net(img)[self.stacks-1], img, center_xyz, M, cube\n",
    "\n",
    "awr_encoder = AwrEncoder(opt).eval()\n",
    "awr_encoder.make_trainable()\n",
    "base_awr_encoder = AwrEncoder(opt).eval()\n",
    "awr_encoder.to(device)\n",
    "\n",
    "for params in awr_encoder.parameters():\n",
    "    if params.requires_grad:\n",
    "        print(f\"{params.shape} requires grad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "0a616e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AwrDecoder()"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AwrDecoder(nn.Module):\n",
    "    def __init__(self, opt):\n",
    "        super(AwrDecoder, self).__init__()\n",
    "        self.config = opt\n",
    "        self.ft_sz = int(self.config.img_size / self.config.downsample)\n",
    "        self.fm = FeatureModule()\n",
    "    \n",
    "    def generate_gt(self, img, jt_xyz_gt, jt_uvd_gt, center_xyz, M, cube):\n",
    "        offset_gt = self.fm.joint2offset(jt_uvd_gt, img, self.config.kernel_size, self.ft_sz)\n",
    "        return torch.Tensor(offset_gt), torch.Tensor(jt_uvd_gt)\n",
    "    \n",
    "    def forward(self, offset_pred, img, center_xyz, M, cube):\n",
    "        jt_uvd_pred = self.fm.offset2joint_softmax(offset_pred, img, self.config.kernel_size)\n",
    "        return offset_pred, jt_uvd_pred\n",
    "\n",
    "awr_decoder = AwrDecoder(opt).eval()\n",
    "awr_decoder.to(device)\n",
    "# get offset_gt from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "cbabfdce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/debabratamandal/Jun-Dec 2021/rnd/exp/HandTailor/checkpoints/model.pt\n",
      "=> Loading checkpoint from local file...\n",
      "Hand2D(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (layer1): Sequential(\n",
      "    (0): BottleneckBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (conv4): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BottleneckBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (conv4): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BottleneckBlock(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (hg2b): ModuleList(\n",
      "    (0): Hourglass(\n",
      "      (hg): ModuleList(\n",
      "        (0): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): BottleneckBlock(\n",
      "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (relu): ReLU()\n",
      "            )\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): BottleneckBlock(\n",
      "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (relu): ReLU()\n",
      "            )\n",
      "          )\n",
      "          (2): Sequential(\n",
      "            (0): BottleneckBlock(\n",
      "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (relu): ReLU()\n",
      "            )\n",
      "          )\n",
      "          (3): Sequential(\n",
      "            (0): BottleneckBlock(\n",
      "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (relu): ReLU()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): BottleneckBlock(\n",
      "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (relu): ReLU()\n",
      "            )\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): BottleneckBlock(\n",
      "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (relu): ReLU()\n",
      "            )\n",
      "          )\n",
      "          (2): Sequential(\n",
      "            (0): BottleneckBlock(\n",
      "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (relu): ReLU()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): BottleneckBlock(\n",
      "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (relu): ReLU()\n",
      "            )\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): BottleneckBlock(\n",
      "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (relu): ReLU()\n",
      "            )\n",
      "          )\n",
      "          (2): Sequential(\n",
      "            (0): BottleneckBlock(\n",
      "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (relu): ReLU()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): BottleneckBlock(\n",
      "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (relu): ReLU()\n",
      "            )\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): BottleneckBlock(\n",
      "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (relu): ReLU()\n",
      "            )\n",
      "          )\n",
      "          (2): Sequential(\n",
      "            (0): BottleneckBlock(\n",
      "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (relu): ReLU()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Hourglass(\n",
      "      (hg): ModuleList(\n",
      "        (0): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): BottleneckBlock(\n",
      "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (relu): ReLU()\n",
      "            )\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): BottleneckBlock(\n",
      "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (relu): ReLU()\n",
      "            )\n",
      "          )\n",
      "          (2): Sequential(\n",
      "            (0): BottleneckBlock(\n",
      "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (relu): ReLU()\n",
      "            )\n",
      "          )\n",
      "          (3): Sequential(\n",
      "            (0): BottleneckBlock(\n",
      "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (relu): ReLU()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): BottleneckBlock(\n",
      "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (relu): ReLU()\n",
      "            )\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): BottleneckBlock(\n",
      "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (relu): ReLU()\n",
      "            )\n",
      "          )\n",
      "          (2): Sequential(\n",
      "            (0): BottleneckBlock(\n",
      "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (relu): ReLU()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): BottleneckBlock(\n",
      "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (relu): ReLU()\n",
      "            )\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): BottleneckBlock(\n",
      "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (relu): ReLU()\n",
      "            )\n",
      "          )\n",
      "          (2): Sequential(\n",
      "            (0): BottleneckBlock(\n",
      "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (relu): ReLU()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): BottleneckBlock(\n",
      "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (relu): ReLU()\n",
      "            )\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): BottleneckBlock(\n",
      "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (relu): ReLU()\n",
      "            )\n",
      "          )\n",
      "          (2): Sequential(\n",
      "            (0): BottleneckBlock(\n",
      "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (relu): ReLU()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (res): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fc): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(277, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(277, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (hm): ModuleList(\n",
      "    (0): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class HandTailorEncoder(nn.Module):\n",
    "    def __init__(self, model, **kwargs):\n",
    "        super(HandTailorEncoder, self).__init__()\n",
    "        self.model = model\n",
    "    \n",
    "    def make_trainable(self):\n",
    "        for idx, (name, params) in enumerate(model.named_parameters()):\n",
    "#             l = len(list(self.model.parameters()))\n",
    "            if \"fc\" in name:\n",
    "                params.requires_grad = False #True\n",
    "            else:\n",
    "                params.requires_grad = False\n",
    "    \n",
    "    def forward(self, frame, img, intr):\n",
    "#         print(\"Image\", img)\n",
    "        hm, enc = self.model(img)\n",
    "#         print(\"HMM\", hm[-1].shape, enc[0].shape, frame)\n",
    "        return (hm, enc), frame, intr\n",
    "\n",
    "# Load from pretrained model\n",
    "# model = HandNet()\n",
    "model = HandNetInTheWild()\n",
    "model = model.to(device)\n",
    "checkpoint_io = CheckpointIO(file_dir, model=model)\n",
    "load_dict = checkpoint_io.load(os.path.join(file_dir, 'checkpoints/model.pt'))\n",
    "\n",
    "kw = {'nstacks':2 , 'nblocks':1, 'njoints':21, 'block':BottleneckBlock}\n",
    "\n",
    "ht_encoder = HandTailorEncoder(model.hand3d.hand2d, **kw).eval()\n",
    "ht_encoder.make_trainable()\n",
    "ht_encoder.to(device)\n",
    "\n",
    "base_ht_encoder = HandTailorEncoder(model.hand3d.hand2d, **kw).eval()\n",
    "base_ht_encoder.to(device)\n",
    "\n",
    "# for params in ht_encoder.parameters():\n",
    "#     print(f\"{params.shape}\", params.requires_grad)\n",
    "    \n",
    "for c in ht_encoder.children():\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "0e7217a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "======================================================================\n",
       "Layer (type:depth-idx)                        Param #\n",
       "======================================================================\n",
       "Hourglass                                     --\n",
       "├─ModuleList: 1-1                             --\n",
       "│    └─ModuleList: 2-1                        --\n",
       "│    │    └─Sequential: 3-1                   (214,528)\n",
       "│    │    └─Sequential: 3-2                   (214,528)\n",
       "│    │    └─Sequential: 3-3                   (214,528)\n",
       "│    │    └─Sequential: 3-4                   (214,528)\n",
       "│    └─ModuleList: 2-2                        --\n",
       "│    │    └─Sequential: 3-5                   (214,528)\n",
       "│    │    └─Sequential: 3-6                   (214,528)\n",
       "│    │    └─Sequential: 3-7                   (214,528)\n",
       "│    └─ModuleList: 2-3                        --\n",
       "│    │    └─Sequential: 3-8                   (214,528)\n",
       "│    │    └─Sequential: 3-9                   (214,528)\n",
       "│    │    └─Sequential: 3-10                  (214,528)\n",
       "│    └─ModuleList: 2-4                        --\n",
       "│    │    └─Sequential: 3-11                  (214,528)\n",
       "│    │    └─Sequential: 3-12                  (214,528)\n",
       "│    │    └─Sequential: 3-13                  (214,528)\n",
       "======================================================================\n",
       "Total params: 2,788,864\n",
       "Trainable params: 0\n",
       "Non-trainable params: 2,788,864\n",
       "======================================================================"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchinfo.summary(model.hand3d.hand2d.hg2b[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "1b0da0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, k in ht_p2.model.hand3d.hand2dto3d.state_dict().items():\n",
    "#     print(i, torch.mean(k))\n",
    "def _uvd2xyz(pts, paras, flip=1):\n",
    "    # paras: (fx, fy, fu, fv)\n",
    "    pts_xyz = pts.copy()\n",
    "    pts_xyz = pts_xyz.reshape(-1, 3).copy()\n",
    "    pts_xyz[:, :2] = (pts_xyz[:, :2] - paras[2:]) * pts_xyz[:, 2:] / paras[:2]\n",
    "    pts_xyz[:, 1] *= flip\n",
    "\n",
    "    return pts_xyz.reshape(pts.shape).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "58f9378d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HandNetInTheWild(\n",
      "  (hand3d): Hand3D(\n",
      "    (hand2dto3d): Hand2Dto3D(\n",
      "      (relu): ReLU()\n",
      "      (sigmoid): Sigmoid()\n",
      "      (hg3d2b): ModuleList(\n",
      "        (0): Hourglass(\n",
      "          (hg): ModuleList(\n",
      "            (0): ModuleList(\n",
      "              (0): Sequential(\n",
      "                (0): BottleneckBlock(\n",
      "                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (relu): ReLU()\n",
      "                )\n",
      "              )\n",
      "              (1): Sequential(\n",
      "                (0): BottleneckBlock(\n",
      "                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (relu): ReLU()\n",
      "                )\n",
      "              )\n",
      "              (2): Sequential(\n",
      "                (0): BottleneckBlock(\n",
      "                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (relu): ReLU()\n",
      "                )\n",
      "              )\n",
      "              (3): Sequential(\n",
      "                (0): BottleneckBlock(\n",
      "                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (relu): ReLU()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): ModuleList(\n",
      "              (0): Sequential(\n",
      "                (0): BottleneckBlock(\n",
      "                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (relu): ReLU()\n",
      "                )\n",
      "              )\n",
      "              (1): Sequential(\n",
      "                (0): BottleneckBlock(\n",
      "                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (relu): ReLU()\n",
      "                )\n",
      "              )\n",
      "              (2): Sequential(\n",
      "                (0): BottleneckBlock(\n",
      "                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (relu): ReLU()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (2): ModuleList(\n",
      "              (0): Sequential(\n",
      "                (0): BottleneckBlock(\n",
      "                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (relu): ReLU()\n",
      "                )\n",
      "              )\n",
      "              (1): Sequential(\n",
      "                (0): BottleneckBlock(\n",
      "                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (relu): ReLU()\n",
      "                )\n",
      "              )\n",
      "              (2): Sequential(\n",
      "                (0): BottleneckBlock(\n",
      "                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (relu): ReLU()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (3): ModuleList(\n",
      "              (0): Sequential(\n",
      "                (0): BottleneckBlock(\n",
      "                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (relu): ReLU()\n",
      "                )\n",
      "              )\n",
      "              (1): Sequential(\n",
      "                (0): BottleneckBlock(\n",
      "                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (relu): ReLU()\n",
      "                )\n",
      "              )\n",
      "              (2): Sequential(\n",
      "                (0): BottleneckBlock(\n",
      "                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (relu): ReLU()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): Hourglass(\n",
      "          (hg): ModuleList(\n",
      "            (0): ModuleList(\n",
      "              (0): Sequential(\n",
      "                (0): BottleneckBlock(\n",
      "                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (relu): ReLU()\n",
      "                )\n",
      "              )\n",
      "              (1): Sequential(\n",
      "                (0): BottleneckBlock(\n",
      "                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (relu): ReLU()\n",
      "                )\n",
      "              )\n",
      "              (2): Sequential(\n",
      "                (0): BottleneckBlock(\n",
      "                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (relu): ReLU()\n",
      "                )\n",
      "              )\n",
      "              (3): Sequential(\n",
      "                (0): BottleneckBlock(\n",
      "                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (relu): ReLU()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): ModuleList(\n",
      "              (0): Sequential(\n",
      "                (0): BottleneckBlock(\n",
      "                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (relu): ReLU()\n",
      "                )\n",
      "              )\n",
      "              (1): Sequential(\n",
      "                (0): BottleneckBlock(\n",
      "                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (relu): ReLU()\n",
      "                )\n",
      "              )\n",
      "              (2): Sequential(\n",
      "                (0): BottleneckBlock(\n",
      "                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (relu): ReLU()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (2): ModuleList(\n",
      "              (0): Sequential(\n",
      "                (0): BottleneckBlock(\n",
      "                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (relu): ReLU()\n",
      "                )\n",
      "              )\n",
      "              (1): Sequential(\n",
      "                (0): BottleneckBlock(\n",
      "                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (relu): ReLU()\n",
      "                )\n",
      "              )\n",
      "              (2): Sequential(\n",
      "                (0): BottleneckBlock(\n",
      "                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (relu): ReLU()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (3): ModuleList(\n",
      "              (0): Sequential(\n",
      "                (0): BottleneckBlock(\n",
      "                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (relu): ReLU()\n",
      "                )\n",
      "              )\n",
      "              (1): Sequential(\n",
      "                (0): BottleneckBlock(\n",
      "                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (relu): ReLU()\n",
      "                )\n",
      "              )\n",
      "              (2): Sequential(\n",
      "                (0): BottleneckBlock(\n",
      "                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (relu): ReLU()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): BottleneckBlock(\n",
      "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU()\n",
      "          )\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): BottleneckBlock(\n",
      "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (fc): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Conv2d(298, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): Conv2d(298, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (hm3d): ModuleList(\n",
      "        (0): Conv2d(256, 42, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(256, 42, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): ResNet18(\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "        (conv4): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  )\n",
      "  (shapereg_layers): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=512, out_features=1024, bias=True)\n",
      "    (7): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU()\n",
      "    (9): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (10): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): ReLU()\n",
      "    (12): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (13): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): ReLU()\n",
      "    (15): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (16): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (17): ReLU()\n",
      "    (18): Linear(in_features=256, out_features=12, bias=True)\n",
      "  )\n",
      "  (sigmoid): Sigmoid()\n",
      "  (iknet): IKNet(\n",
      "    (invk_layers): Sequential(\n",
      "      (0): Linear(in_features=63, out_features=256, bias=True)\n",
      "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Linear(in_features=256, out_features=512, bias=True)\n",
      "      (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU()\n",
      "      (6): Linear(in_features=512, out_features=1024, bias=True)\n",
      "      (7): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (8): ReLU()\n",
      "      (9): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (10): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (11): ReLU()\n",
      "      (12): Linear(in_features=1024, out_features=512, bias=True)\n",
      "      (13): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (14): ReLU()\n",
      "      (15): Linear(in_features=512, out_features=256, bias=True)\n",
      "      (16): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (17): ReLU()\n",
      "      (18): Linear(in_features=256, out_features=64, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class HandTailorDecoderA(nn.Module):\n",
    "    def __init__(self, model, custom=True, wild=False):\n",
    "        super(HandTailorDecoderA, self).__init__()\n",
    "        if wild:\n",
    "            self.model = HandNetInTheWild(custom=custom)\n",
    "        else:\n",
    "            self.model = HandNet(custom=custom)\n",
    "\n",
    "    def init_weights(self, saved_model):\n",
    "#         self.model.decoder = saved_model.decoder\n",
    "        self.model.ref_bone_link = saved_model.ref_bone_link\n",
    "        self.model.joint_root_idx = saved_model.joint_root_idx\n",
    "        self.model.hand3d.hand2dto3d.load_state_dict(saved_model.hand3d.hand2dto3d.state_dict())\n",
    "        self.model.decoder.load_state_dict(saved_model.decoder.state_dict())\n",
    "        self.model.iknet.load_state_dict(saved_model.iknet.state_dict())\n",
    "        self.model.sigmoid.load_state_dict(saved_model.sigmoid.state_dict())\n",
    "        self.model.shapereg_layers.load_state_dict(saved_model.shapereg_layers.state_dict())\n",
    "\n",
    "    def make_trainable(self):\n",
    "        for idx, param in enumerate(self.model.parameters()):\n",
    "#             l = len(list(self.model.parameters()))\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, x, frame, intr):\n",
    "        hm, so3, beta, joint_root, bone = self.model(x, intr)\n",
    "#         print(\"HM\", hm)\n",
    "        batch_size = intr.shape[0]\n",
    "        camparam = np.zeros((batch_size, 21, 4))\n",
    "#         print(intr)\n",
    "        camparam[:, :, 0] = np.reshape(intr[:, 0, 0], (batch_size, 1))\n",
    "        camparam[:, :, 1] = np.reshape(intr[:, 1, 1], (batch_size, 1))\n",
    "        camparam[:, :, 2] = np.reshape(intr[:, 0, 2], (batch_size, 1))\n",
    "        camparam[:, :, 3] = np.reshape(intr[:, 1, 2], (batch_size, 1))\n",
    "        _so3 = so3\n",
    "        _beta = beta\n",
    "        bone = bone[0]\n",
    "        joint_root = joint_root[0]\n",
    "        so3 = np.array(so3[0].detach())\n",
    "        beta = np.array(beta[0].detach())\n",
    "        joint = mano_de_j(so3, beta)\n",
    "#         print(joint*256, uvd2xyz1(joint, camparam[0, 0, :]))\n",
    "        return joint, hm, camparam, bone, joint_root, _so3, _beta, frame, intr\n",
    "\n",
    "kw = {'custom': True, 'wild': True}\n",
    "ht_decoder1 = HandTailorDecoderA(model, **kw)\n",
    "ht_decoder1.make_trainable()\n",
    "ht_decoder1.eval()\n",
    "ht_decoder1.init_weights(model)\n",
    "\n",
    "ht_decoder1.to(device)\n",
    "# for i, k in model.hand3d.hand2dto3d.state_dict().items():\n",
    "#     print(i, torch.mean(k))\n",
    "# print(model.hand3d.hand2dto3d.state_dict())\n",
    "\n",
    "test = torch.rand([1, 256, 64, 64])\n",
    "# print(torch.mean(model.hand3d.hand2dto3d(test)[0]))\n",
    "# print(torch.mean(ht_p2.model.hand3d.hand2dto3d(test)[0]))\n",
    "\n",
    "# for params in ht_decoder1.parameters():\n",
    "#     if params.requires_grad:\n",
    "#     print(f\"{params.shape} requires grad\")\n",
    "    \n",
    "    \n",
    "for c in ht_decoder1.children():\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "b21bcb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ht_p3(joint, hm, camparam, bone, joint_root, so3, beta, frame, intr):\n",
    "#     print(\"hand3d\", torch.mean(hm), torch.mean(so3))\n",
    "    kp2d = hm_to_kp2d(hm.detach().numpy())*4\n",
    "    kp2d = npj.array(kp2d)\n",
    "    so3 = npj.array(so3[0].detach())\n",
    "    beta = npj.array(beta[0].detach())\n",
    "    joint_root = npj.array(joint_root.detach())\n",
    "    joint_root = reinit_root(joint_root,kp2d, camparam)\n",
    "    bone = npj.array(bone.detach())\n",
    "    gr = jit(grad(residuals))\n",
    "    lr = 0.03\n",
    "    opt_init, opt_update, get_params = optimizers.adam(lr, b1=0.5, b2=0.5)\n",
    "    opt_init = jit(opt_init)\n",
    "    opt_update = jit(opt_update)\n",
    "    get_params = jit(get_params)\n",
    "    so3_init = so3\n",
    "    beta_init = beta\n",
    "    bone = reinit_scale(joint,kp2d,camparam,bone,joint_root)\n",
    "    params = {'so3':so3, 'beta':beta, 'bone':bone}\n",
    "    opt_state = opt_init(params)\n",
    "    n = 0\n",
    "    while n < 20:\n",
    "        n = n + 1\n",
    "        params = get_params(opt_state)\n",
    "        grads = gr(params,so3_init,beta_init,joint_root,kp2d,camparam)\n",
    "        opt_state = opt_update(n, grads, opt_state)\n",
    "    params = get_params(opt_state)\n",
    "    v = mano_de(params,joint_root,bone)\n",
    "#     print(torch.mean(torch.Tensor(np.array(v))))\n",
    "    return v, intr, frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "12e4423e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ht_wild_p3(joint, hm, camparam, bone, joint_root, so3, beta, frame, intr):\n",
    "#     print(\"hand3d\", torch.mean(hm), torch.mean(so3))\n",
    "    kp2d = hm_to_kp2d(hm.detach().cpu().numpy())*4\n",
    "    kp2d = npj.array(kp2d)\n",
    "    t = kp2d[0,9,:]\n",
    "    so3 = so3[0].detach().cpu().float().numpy()\n",
    "    beta = beta[0].detach().cpu().float().numpy()\n",
    "    bone = bone[0].detach().cpu().numpy()\n",
    "    joint_root = joint_root[0].detach().cpu().numpy()\n",
    "    so3 = npj.array(so3)\n",
    "    beta = npj.array(beta)\n",
    "    bone = npj.array(bone)\n",
    "    joint_root = npj.array(joint_root)\n",
    "    gr = jit(grad(residuals))\n",
    "    lr = 0.03\n",
    "    opt_init, opt_update, get_params = optimizers.adam(lr, b1=0.5, b2=0.5)\n",
    "    opt_init = jit(opt_init)\n",
    "    opt_update = jit(opt_update)\n",
    "    get_params = jit(get_params)\n",
    "    so3_init = so3\n",
    "    beta_init = beta\n",
    "    s = reinit_scale(joint,kp2d,t)\n",
    "    params = {'so3':so3, 'beta':beta}\n",
    "    so3 = params['so3']\n",
    "    beta = params['beta']\n",
    "    opt_state = opt_init(params)\n",
    "\n",
    "    n = 0\n",
    "    while n < 20:\n",
    "        n = n + 1\n",
    "        params = get_params(opt_state)\n",
    "        grads = gr(params,so3_init,beta_init,kp2d,s,t)\n",
    "        opt_state = opt_update(n, grads, opt_state)\n",
    "        joint = mano_de_j(so3, beta)\n",
    "        s = reinit_scale(joint,kp2d,t)\n",
    "    params = get_params(opt_state)\n",
    "    so3 = params['so3']\n",
    "    beta = params['beta']\n",
    "    v = mano_de(so3, beta)\n",
    "    v = v*s + np.array([t[0],t[1],0])\n",
    "    return v, intr, frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "cb52198c",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.path.curdir\n",
    "awr_dir = os.path.join(root_dir, 'AWR/')\n",
    "os.makedirs(awr_dir, exist_ok=True)\n",
    "\n",
    "handtailor_dir = os.path.join(root_dir, 'HandTailor/')\n",
    "os.makedirs(handtailor_dir, exist_ok=True)\n",
    "\n",
    "data_dir = os.path.join(root_dir, 'data/')\n",
    "awr_data_dir = os.path.join(data_dir, 'nyu/')\n",
    "ht_data_dir = os.path.join(data_dir, 'RHD_published_v2/')\n",
    "\n",
    "fig_dir = os.path.join(root_dir, 'figures/')\n",
    "os.makedirs(fig_dir, exist_ok=True)\n",
    "\n",
    "awr_fig_dir = os.path.join(fig_dir, 'awr/')\n",
    "ht_fig_dir = os.path.join(fig_dir, 'handtailor/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "f7b1b3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedImageDataset(Dataset):\n",
    "    def __init__(self, dataset_A, dataset_B, gt_A, gt_B):\n",
    "        self.dataset_A = dataset_A\n",
    "        self.dataset_B = dataset_B\n",
    "        self.gt_A = gt_A\n",
    "        self.gt_B = gt_B\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # Hardcode\n",
    "#         print(index)\n",
    "        item_A = self.dataset_A[index % len(self.dataset_A)]\n",
    "        item_B = self.dataset_B[index % len(self.dataset_B)]\n",
    "#         print(index, len(self.dataset_A))\n",
    "        gt_A = self.gt_A[index // BATCH_SIZE][index % BATCH_SIZE]\n",
    "        gt_B = self.gt_B[index // BATCH_SIZE][index % BATCH_SIZE]\n",
    "#         return {\"A\": item_A, \"gt_A\": gt_A, \"B\": item_B, \"gt_B\": gt_B}\n",
    "        return (item_A, gt_A, item_B, gt_B)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return max(len(self.dataset_A), len(self.dataset_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "c899a278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset, containing 99 images.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1, 128, 128), (14, 3), (14, 3), (3,), (3, 3), (3,)]"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset A - AWR\n",
    "\n",
    "awr_data_dir = os.path.join(opt.data_dir, opt.dataset)\n",
    "nyu_test = NYU(awr_data_dir, 'test', img_size=opt.img_size, cube=opt.cube)\n",
    "# nyu_train = NYU(awr_data_dir, 'train', img_size=opt.img_size, cube=opt.cube)\n",
    "\n",
    "# print(d1[0])\n",
    "[x.shape for x in nyu_test[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "e79e88e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W ParallelNative.cpp:212] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:212] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:212] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:212] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:212] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:212] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:212] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:212] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:212] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:212] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:212] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:212] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:212] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:212] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:212] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:212] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:212] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:212] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:212] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:212] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:212] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:212] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:212] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:212] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:212] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:212] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:212] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:212] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:212] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:212] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:212] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:212] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:212] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:212] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:212] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:212] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate ground truth annotations A\n",
    "# d1_loader = DataLoader(d1, batch_size=BATCH_SIZE, drop_last=True, shuffle=False)\n",
    "nyu_loader = DataLoader(nyu_test, batch_size=BATCH_SIZE, drop_last=True, shuffle=SHUFFLE, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "\n",
    "gt_A = []\n",
    "for i in range(len(nyu_loader)):\n",
    "    _gt = next(iter(nyu_loader))\n",
    "    offset_gt, jt_uvd_gt = awr_decoder.generate_gt(*_gt)\n",
    "    gt_A += [jt_uvd_gt]\n",
    "\n",
    "len(gt_A)\n",
    "len(nyu_loader)\n",
    "# with open(os.path.join(awr_data_dir, 'gt_A.npy'), 'wb') as gt_A:\n",
    "#     np.save(gt_A, np.array(gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "c2d6d2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "20e76474",
   "metadata": {},
   "outputs": [],
   "source": [
    "i += 1\n",
    "assert(i<9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "7ed918ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1  1  1]\n",
      " [ 1  1  1]\n",
      " [ 1  1  1]]\n"
     ]
    }
   ],
   "source": [
    "scal = np.ones((3, 3), dtype=int)\n",
    "r = i//3\n",
    "c = i%3\n",
    "scal[r, c] = -1\n",
    "print(scal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "7ff9f0fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2728 dict_keys(['K', 'xyz', 'uv_vis']) [[282.9   0.  160. ]\n",
      " [  0.  282.9 160. ]\n",
      " [  0.    0.    1. ]]\n",
      "81.75114\n",
      "[[158.    136.9     1.   ]\n",
      " [153.2   174.7     1.   ]\n",
      " [150.4   166.3     1.   ]\n",
      " [147.4   154.      1.   ]\n",
      " [151.4   145.4     1.   ]\n",
      " [170.6   174.9     1.   ]\n",
      " [167.4   167.9     1.   ]\n",
      " [163.8   158.3     1.   ]\n",
      " [159.2   150.5     1.   ]\n",
      " [171.8   191.3     1.   ]\n",
      " [172.7   177.4     1.   ]\n",
      " [173.1   164.3     1.   ]\n",
      " [169.6   151.9     1.   ]\n",
      " [177.3   188.6     1.   ]\n",
      " [178.2   174.8     1.   ]\n",
      " [178.6   163.7     1.   ]\n",
      " [175.8   152.9     1.   ]\n",
      " [188.4   182.6     1.   ]\n",
      " [188.2   175.2     1.   ]\n",
      " [187.5   167.2     1.   ]\n",
      " [181.4   155.1     1.   ]\n",
      " [-13.56  152.5     0.   ]\n",
      " [ -2.058 181.6     0.   ]\n",
      " [ -1.16  177.3     0.   ]\n",
      " [ -2.59  166.5     0.   ]\n",
      " [ -4.869 158.1     0.   ]\n",
      " [-17.24  196.5     0.   ]\n",
      " [-18.19  187.6     0.   ]\n",
      " [-20.05  175.7     0.   ]\n",
      " [-17.54  165.8     0.   ]\n",
      " [-38.35  200.4     0.   ]\n",
      " [-34.96  190.9     0.   ]\n",
      " [-33.55  181.      0.   ]\n",
      " [-27.69  171.2     0.   ]\n",
      " [-46.61  200.5     0.   ]\n",
      " [-41.87  191.9     0.   ]\n",
      " [-38.65  183.7     0.   ]\n",
      " [-33.16  174.7     0.   ]\n",
      " [-48.77  198.1     0.   ]\n",
      " [-46.59  192.1     0.   ]\n",
      " [-45.07  186.4     0.   ]\n",
      " [-36.93  178.7     0.   ]]\n"
     ]
    }
   ],
   "source": [
    "ht_set = \"evaluation\"\n",
    "ht_eval_dir = os.path.join(ht_data_dir, ht_set)\n",
    "with open(os.path.join(ht_eval_dir, 'anno_%s.pickle' % ht_set), 'rb') as fi:\n",
    "    anno_all = pickle.load(fi)\n",
    "print(len(anno_all), anno_all[0].keys(), anno_all[0]['K'])\n",
    "print(np.mean(anno_all[0]['uv_vis']))\n",
    "print(anno_all[0]['uv_vis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "2acba1a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1107"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rhd_right_samples = []\n",
    "for idx, anno in anno_all.items():\n",
    "    if not anno['uv_vis'][0, 2]:\n",
    "        rhd_right_samples.append(idx)\n",
    "len(rhd_right_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "31bdfba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "d = { ... }\n",
    "d2 = copy.deepcopy(d)\n",
    "anno_all_copy = copy.deepcopy(anno_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "7b0e6bc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2728"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset B  - HandTailor\n",
    "\n",
    "# experimental\n",
    "# ht_data_dir = os.path.join(opt.data_dir, opt.dataset)\n",
    "\n",
    "anno_all = anno_all_copy\n",
    "\n",
    "class RenderedHandPose(Dataset):\n",
    "    def __init__(self, img_dir, anno_all):\n",
    "        self.img_list = [os.path.join(img_dir, 'color', '%.5d.png' % idx) for idx, _ in anno_all.items()]\n",
    "        self.anno = [anno for _, anno in anno_all.items()]\n",
    "#         self.img_list = []\n",
    "#         self.anno = []\n",
    "#         for idx, anno in anno_all.items():\n",
    "#             if not anno['uv_vis'][-1, 2]:\n",
    "#                 self.img_list.append(os.path.join(img_dir, 'color', '%.5d.png' % idx))\n",
    "#                 self.anno.append(anno)\n",
    "    \n",
    "    def transform(self, img, K):\n",
    "#         if flip:\n",
    "#         img = np.flip(img, 1)\n",
    "# #         arg = dotdict({'cx':K[0, 2], 'cy':-K[1, 2], 'fx':-K[0, 0], 'fy':-K[1, 1]})\n",
    "# #         else\n",
    "#         print(\"KMat\", K)\n",
    "        arg = dotdict({'cx':K[0, 2], 'cy':K[1, 2], 'fx':K[0, 0], 'fy':K[1, 1]})\n",
    "        frame, img, intr = preprocess(img, arg)\n",
    "        return frame, img[0], intr[0]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        index = 23\n",
    "        index = index % len(self.img_list)\n",
    "#         print(self.anno[index]['xyz'])\n",
    "        flip = self.anno[index]['uv_vis'][0, 2]\n",
    "#         print(flip, \"fli\")\n",
    "#         self.anno[index]['K'] = np.array(np.array(self.anno[index]['K'], dtype=float) * scal, dtype=float)\n",
    "#         for i in range(9):\n",
    "#             self.anno[index]['K'][i//3][i%3] *= scal[i//3][i%3]\n",
    "#         self.anno[index]['K'][1, 1] *= -1\n",
    "#         self.anno[index]['K'][0, 0] *= -1\n",
    "#         self.anno[index]['K'][0, 2] *= -1\n",
    "#         self.anno[index]['K'][1, 2] *= -1\n",
    "        ann = np.array([[0]*3]*3)\n",
    "#         ann[0, 0] = self.anno[index]['K'][0, 0] * -1\n",
    "#         ann[1, 1] = self.anno[index]['K'][1, 1]\n",
    "#         ann[0, 2] = self.anno[index]['K'][0, 2]\n",
    "#         ann[1, 2] = self.anno[index]['K'][1, 2]\n",
    "#         self.anno[index]['K'] = ann\n",
    "        return self.transform(imageio.imread(self.img_list[index]), self.anno[index]['K']), self.anno[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "        \n",
    "# arg = {'cx': 321.2842102050781, 'cy': 235.8609161376953, 'fx': 612.0206298828125, 'fy': 612.2821044921875}\n",
    "rhd_test = RenderedHandPose(ht_eval_dir, anno_all)\n",
    "# d2 = HandTailorDataset('HandTailor/demo/', dotdict(arg), mode=\"test\")\n",
    "\n",
    "assert(len(rhd_test[-1][-2]) == 3)\n",
    "[x.shape for x in rhd_test[-1][-2]]\n",
    "\n",
    "len(rhd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "75e491aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate ground truth annotations B\n",
    "\n",
    "SCALE = 256 / 320\n",
    "\n",
    "def generate_gt_B(anno):\n",
    "    gt_xyz = []\n",
    "    gt_uv_proj = []\n",
    "    gt_vs = []\n",
    "    gt_uv = []\n",
    "    for idx in range(len(anno['K'])):\n",
    "        ## REMOVE THIS ##\n",
    "        if idx>23:\n",
    "            break\n",
    "        kp_coord_uv = anno['uv_vis'][idx][:, :2]\n",
    "        kp_visible = (anno['uv_vis'][idx][:, 2] == 1) * 1.0\n",
    "        kp_coord_xyz = anno['xyz'][idx]\n",
    "\n",
    "        camera_intrinsic_matrix = anno['K'][idx].to(torch.float)\n",
    "\n",
    "        kp_coord_uv_proj = np.matmul(kp_coord_xyz, np.transpose(camera_intrinsic_matrix))\n",
    "        kp_coord_uv_proj = kp_coord_uv_proj[:, :2] / kp_coord_uv_proj[:, 2:]\n",
    "#         gt.append((kp_coord_xyz, kp_coord_uv_proj))\n",
    "        gt_xyz.append(torch.Tensor(kp_coord_xyz))\n",
    "        gt_uv_proj.append(torch.Tensor(kp_coord_uv_proj)*SCALE)\n",
    "        gt_vs.append(torch.Tensor(kp_visible))\n",
    "        gt_uv.append(torch.Tensor(kp_coord_uv)*SCALE)\n",
    "    \n",
    "    return gt_xyz, gt_uv, gt_vs, gt_uv_proj\n",
    "\n",
    "# Need a batch size of 2\n",
    "rhd_loader = DataLoader(rhd_test, batch_size=BATCH_SIZE, drop_last=True, shuffle=SHUFFLE, pin_memory=PIN_MEMORY)\n",
    "gt_B = []\n",
    "for i in range(len(rhd_loader)):\n",
    "    _, y = next(iter(rhd_loader))\n",
    "    gt_xyz, *_ = generate_gt_B(y)\n",
    "    gt_B += [gt_xyz]\n",
    "#     *_, _gt_jt_root, _gt_so3, _gt_beta, _, _ = ht_p2(*base_ht_p1.forward(*_gt))\n",
    "#     gt_B.append(_gt_beta[0])\n",
    "#     gt_B.append(_gt_beta[1])\n",
    "\n",
    "# with open(os.path.join(data_dir, 'gt_B.npy'), 'wb') as gt_B:\n",
    "#     np.save(gt_B, np.array(gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "12012db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272\n"
     ]
    }
   ],
   "source": [
    "print(len(gt_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "a1953ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = CombinedImageDataset(nyu_test, rhd_test, gt_A, gt_B)\n",
    "len(test_ds)\n",
    "\n",
    "assert test_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "3794e500",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(test_ds, batch_size=BATCH_SIZE, drop_last=True, shuffle=SHUFFLE, pin_memory=PIN_MEMORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "1412bcee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[tensor([[[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "            [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "            [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "            ...,\n",
       "            [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "            [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "            [1., 1., 1.,  ..., 1., 1., 1.]]],\n",
       "  \n",
       "  \n",
       "          [[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "            [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "            [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "            ...,\n",
       "            [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "            [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "            [1., 1., 1.,  ..., 1., 1., 1.]]],\n",
       "  \n",
       "  \n",
       "          [[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "            [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "            [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "            ...,\n",
       "            [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "            [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "            [1., 1., 1.,  ..., 1., 1., 1.]]],\n",
       "  \n",
       "  \n",
       "          ...,\n",
       "  \n",
       "  \n",
       "          [[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "            [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "            [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "            ...,\n",
       "            [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "            [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "            [1., 1., 1.,  ..., 1., 1., 1.]]],\n",
       "  \n",
       "  \n",
       "          [[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "            [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "            [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "            ...,\n",
       "            [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "            [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "            [1., 1., 1.,  ..., 1., 1., 1.]]],\n",
       "  \n",
       "  \n",
       "          [[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "            [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "            [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "            ...,\n",
       "            [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "            [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "            [1., 1., 1.,  ..., 1., 1., 1.]]]]),\n",
       "  tensor([[[-2.7072e-01,  4.5582e-01, -2.0619e-01],\n",
       "           [-2.3990e-01,  1.8671e-01, -1.3921e-01],\n",
       "           [-1.0715e-02,  6.4915e-01, -1.6169e-01],\n",
       "           [-6.2844e-02,  3.2406e-01, -1.0043e-01],\n",
       "           [ 1.7125e-01,  7.1920e-01, -1.3867e-01],\n",
       "           [ 8.5996e-02,  3.7390e-01, -4.2469e-02],\n",
       "           [ 3.6016e-01,  6.2034e-01, -1.4218e-01],\n",
       "           [ 2.9927e-01,  3.0578e-01, -4.8495e-02],\n",
       "           [ 5.8840e-01,  2.1619e-03, -2.1193e-01],\n",
       "           [ 5.5014e-01, -1.2983e-01, -1.4609e-01],\n",
       "           [ 3.9843e-01, -3.5341e-01, -6.4043e-02],\n",
       "           [-1.8639e-01, -6.3052e-01,  3.8236e-02],\n",
       "           [ 4.2313e-02, -6.8655e-01,  4.2264e-02],\n",
       "           [ 5.3770e-02, -1.4645e-01, -3.3700e-03]],\n",
       "  \n",
       "          [[-2.6565e-01,  4.5786e-01, -2.2115e-01],\n",
       "           [-2.3483e-01,  1.8875e-01, -1.5417e-01],\n",
       "           [-5.6502e-03,  6.5119e-01, -1.7665e-01],\n",
       "           [-5.7779e-02,  3.2610e-01, -1.1539e-01],\n",
       "           [ 1.7631e-01,  7.2124e-01, -1.5363e-01],\n",
       "           [ 9.1061e-02,  3.7594e-01, -5.7424e-02],\n",
       "           [ 3.6523e-01,  6.2237e-01, -1.5713e-01],\n",
       "           [ 3.0433e-01,  3.0782e-01, -6.3450e-02],\n",
       "           [ 5.9346e-01,  4.1977e-03, -2.2688e-01],\n",
       "           [ 5.5521e-01, -1.2779e-01, -1.6104e-01],\n",
       "           [ 4.0349e-01, -3.5137e-01, -7.8997e-02],\n",
       "           [-1.8133e-01, -6.2848e-01,  2.3282e-02],\n",
       "           [ 4.7378e-02, -6.8451e-01,  2.7309e-02],\n",
       "           [ 5.8834e-02, -1.4442e-01, -1.8324e-02]],\n",
       "  \n",
       "          [[-2.6526e-01,  4.5710e-01, -2.2099e-01],\n",
       "           [-2.3450e-01,  1.8810e-01, -1.5360e-01],\n",
       "           [-5.2025e-03,  6.5054e-01, -1.7631e-01],\n",
       "           [-5.7377e-02,  3.2546e-01, -1.1500e-01],\n",
       "           [ 1.7688e-01,  7.2033e-01, -1.5428e-01],\n",
       "           [ 9.1462e-02,  3.7528e-01, -5.7131e-02],\n",
       "           [ 3.6574e-01,  6.2170e-01, -1.5679e-01],\n",
       "           [ 3.0478e-01,  3.0716e-01, -6.3131e-02],\n",
       "           [ 5.9385e-01,  3.3694e-03, -2.2679e-01],\n",
       "           [ 5.5563e-01, -1.2859e-01, -1.6086e-01],\n",
       "           [ 4.0389e-01, -3.5208e-01, -7.8681e-02],\n",
       "           [-1.8097e-01, -6.2913e-01,  2.3590e-02],\n",
       "           [ 4.7741e-02, -6.8516e-01,  2.7615e-02],\n",
       "           [ 5.9198e-02, -1.4507e-01, -1.8015e-02]],\n",
       "  \n",
       "          [[-2.6740e-01,  4.5966e-01, -2.1267e-01],\n",
       "           [-2.3796e-01,  1.8540e-01, -1.5059e-01],\n",
       "           [-8.8204e-03,  6.4988e-01, -1.7344e-01],\n",
       "           [-6.1123e-02,  3.2487e-01, -1.1192e-01],\n",
       "           [ 1.7317e-01,  7.1961e-01, -1.5163e-01],\n",
       "           [ 8.7654e-02,  3.7467e-01, -5.4105e-02],\n",
       "           [ 3.6194e-01,  6.2108e-01, -1.5374e-01],\n",
       "           [ 3.0097e-01,  3.0654e-01, -6.0068e-02],\n",
       "           [ 5.8967e-01,  2.7259e-03, -2.2379e-01],\n",
       "           [ 5.5174e-01, -1.2927e-01, -1.5777e-01],\n",
       "           [ 4.0006e-01, -3.5269e-01, -7.5607e-02],\n",
       "           [-1.8480e-01, -6.2975e-01,  2.6631e-02],\n",
       "           [ 4.3906e-02, -6.8578e-01,  3.0671e-02],\n",
       "           [ 5.5367e-02, -1.4568e-01, -1.4957e-02]],\n",
       "  \n",
       "          [[-2.6909e-01,  4.5840e-01, -2.1839e-01],\n",
       "           [-2.3947e-01,  1.8412e-01, -1.5651e-01],\n",
       "           [-1.0420e-02,  6.4862e-01, -1.7991e-01],\n",
       "           [-6.2604e-02,  3.2355e-01, -1.1769e-01],\n",
       "           [ 1.7029e-01,  7.2019e-01, -1.4641e-01],\n",
       "           [ 8.5884e-02,  3.7323e-01, -5.6241e-02],\n",
       "           [ 3.6051e-01,  6.1979e-01, -1.5987e-01],\n",
       "           [ 2.9956e-01,  3.0526e-01, -6.6144e-02],\n",
       "           [ 5.8816e-01,  1.5429e-03, -2.2956e-01],\n",
       "           [ 5.5034e-01, -1.3053e-01, -1.6364e-01],\n",
       "           [ 3.9871e-01, -3.5404e-01, -8.1734e-02],\n",
       "           [-1.8616e-01, -6.3105e-01,  2.0570e-02],\n",
       "           [ 4.2553e-02, -6.8708e-01,  2.4590e-02],\n",
       "           [ 5.3996e-02, -1.4698e-01, -2.1024e-02]],\n",
       "  \n",
       "          [[-2.6572e-01,  4.5921e-01, -2.1533e-01],\n",
       "           [-2.3672e-01,  1.8421e-01, -1.5620e-01],\n",
       "           [-7.0002e-03,  6.4813e-01, -1.7997e-01],\n",
       "           [-5.9560e-02,  3.2305e-01, -1.1809e-01],\n",
       "           [ 1.6667e-01,  7.1873e-01, -1.5481e-01],\n",
       "           [ 8.5654e-02,  3.7211e-01, -5.9905e-02],\n",
       "           [ 3.6375e-01,  6.1635e-01, -1.6903e-01],\n",
       "           [ 3.0266e-01,  3.0366e-01, -6.7396e-02],\n",
       "           [ 5.9005e-01, -1.9724e-03, -2.3525e-01],\n",
       "           [ 5.5226e-01, -1.3375e-01, -1.6871e-01],\n",
       "           [ 4.0063e-01, -3.5663e-01, -8.4970e-02],\n",
       "           [-1.8496e-01, -6.3141e-01,  2.1722e-02],\n",
       "           [ 4.3647e-02, -6.8790e-01,  2.4840e-02],\n",
       "           [ 5.6004e-02, -1.4791e-01, -2.1765e-02]],\n",
       "  \n",
       "          [[-2.6477e-01,  4.5900e-01, -2.1597e-01],\n",
       "           [-2.3557e-01,  1.8418e-01, -1.5615e-01],\n",
       "           [-5.5640e-03,  6.4861e-01, -1.7959e-01],\n",
       "           [-5.8060e-02,  3.2343e-01, -1.1805e-01],\n",
       "           [ 1.6817e-01,  7.1911e-01, -1.5473e-01],\n",
       "           [ 8.7138e-02,  3.7249e-01, -5.9830e-02],\n",
       "           [ 3.6225e-01,  6.1763e-01, -1.7043e-01],\n",
       "           [ 3.0254e-01,  3.0479e-01, -6.8481e-02],\n",
       "           [ 5.9124e-01, -1.6098e-03, -2.3521e-01],\n",
       "           [ 5.5369e-01, -1.3342e-01, -1.6862e-01],\n",
       "           [ 4.0215e-01, -3.5628e-01, -8.4891e-02],\n",
       "           [-1.8348e-01, -6.3102e-01,  2.1760e-02],\n",
       "           [ 4.5123e-02, -6.8751e-01,  2.4924e-02],\n",
       "           [ 5.7486e-02, -1.4752e-01, -2.1700e-02]],\n",
       "  \n",
       "          [[-2.6664e-01,  4.5837e-01, -2.0394e-01],\n",
       "           [-2.3774e-01,  1.8341e-01, -1.4462e-01],\n",
       "           [-8.1229e-03,  6.4764e-01, -1.6840e-01],\n",
       "           [-6.0570e-02,  3.2253e-01, -1.0642e-01],\n",
       "           [ 1.7049e-01,  7.1790e-01, -1.4293e-01],\n",
       "           [ 8.7502e-02,  3.7166e-01, -4.8341e-02],\n",
       "           [ 3.5989e-01,  6.1668e-01, -1.5863e-01],\n",
       "           [ 3.0010e-01,  3.0381e-01, -5.6840e-02],\n",
       "           [ 5.8890e-01, -2.6633e-03, -2.2311e-01],\n",
       "           [ 5.5129e-01, -1.3446e-01, -1.5650e-01],\n",
       "           [ 3.9962e-01, -3.5725e-01, -7.2878e-02],\n",
       "           [-1.8615e-01, -6.3184e-01,  3.3391e-02],\n",
       "           [ 4.2443e-02, -6.8838e-01,  3.6765e-02],\n",
       "           [ 5.4954e-02, -1.4841e-01, -1.0054e-02]],\n",
       "  \n",
       "          [[-2.6553e-01,  4.5949e-01, -2.0513e-01],\n",
       "           [-2.3671e-01,  1.8363e-01, -1.4903e-01],\n",
       "           [-7.9804e-03,  6.4851e-01, -1.7158e-01],\n",
       "           [-6.0140e-02,  3.2308e-01, -1.1101e-01],\n",
       "           [ 1.7334e-01,  7.1821e-01, -1.4601e-01],\n",
       "           [ 8.9278e-02,  3.7213e-01, -5.1713e-02],\n",
       "           [ 3.6286e-01,  6.2026e-01, -1.5201e-01],\n",
       "           [ 3.0118e-01,  3.0449e-01, -6.0283e-02],\n",
       "           [ 5.9060e-01, -2.5611e-03, -2.2271e-01],\n",
       "           [ 5.5288e-01, -1.3422e-01, -1.5590e-01],\n",
       "           [ 4.0066e-01, -3.5676e-01, -7.3068e-02],\n",
       "           [-1.8583e-01, -6.3136e-01,  2.8479e-02],\n",
       "           [ 4.2761e-02, -6.8775e-01,  3.4017e-02],\n",
       "           [ 5.5375e-02, -1.4790e-01, -1.4095e-02]],\n",
       "  \n",
       "          [[-2.5955e-01,  4.6119e-01, -2.1603e-01],\n",
       "           [-2.3009e-01,  1.8537e-01, -1.6005e-01],\n",
       "           [-4.0985e-04,  6.5049e-01, -1.8328e-01],\n",
       "           [-5.2820e-02,  3.2536e-01, -1.2133e-01],\n",
       "           [ 1.8167e-01,  7.1890e-01, -1.6241e-01],\n",
       "           [ 9.6297e-02,  3.7441e-01, -6.2197e-02],\n",
       "           [ 3.7060e-01,  6.2185e-01, -1.6747e-01],\n",
       "           [ 3.0871e-01,  3.0668e-01, -7.3837e-02],\n",
       "           [ 5.9804e-01, -4.1265e-04, -2.3396e-01],\n",
       "           [ 5.6027e-01, -1.3210e-01, -1.6724e-01],\n",
       "           [ 4.0803e-01, -3.5470e-01, -8.4578e-02],\n",
       "           [-1.7843e-01, -6.2912e-01,  1.7308e-02],\n",
       "           [ 5.0169e-02, -6.8550e-01,  2.2686e-02],\n",
       "           [ 6.2724e-02, -1.4565e-01, -2.5477e-02]]]),\n",
       "  tensor([[[-3.1785e-01, -4.7045e-01, -2.0619e-01],\n",
       "           [-2.6989e-01, -1.8959e-01, -1.3921e-01],\n",
       "           [-3.8962e-02, -6.6592e-01, -1.6169e-01],\n",
       "           [-8.0626e-02, -3.2838e-01, -1.0043e-01],\n",
       "           [ 1.5203e-01, -7.3496e-01, -1.3867e-01],\n",
       "           [ 8.0295e-02, -3.7566e-01, -4.2469e-02],\n",
       "           [ 3.4545e-01, -6.3409e-01, -1.4218e-01],\n",
       "           [ 2.9420e-01, -3.0749e-01, -4.8495e-02],\n",
       "           [ 5.7535e-01,  7.3123e-04, -2.1193e-01],\n",
       "           [ 5.4021e-01,  1.3496e-01, -1.4609e-01],\n",
       "           [ 3.9257e-01,  3.5693e-01, -6.4043e-02],\n",
       "           [-1.7675e-01,  6.2208e-01,  3.8236e-02],\n",
       "           [ 5.0424e-02,  6.7688e-01,  4.2264e-02],\n",
       "           [ 5.4335e-02,  1.4532e-01, -3.3700e-03]],\n",
       "  \n",
       "          [[-3.1490e-01, -4.7682e-01, -2.2115e-01],\n",
       "           [-2.6673e-01, -1.9474e-01, -1.5417e-01],\n",
       "           [-3.4802e-02, -6.7313e-01, -1.7665e-01],\n",
       "           [-7.6647e-02, -3.3413e-01, -1.1539e-01],\n",
       "           [ 1.5702e-01, -7.4247e-01, -1.5363e-01],\n",
       "           [ 8.4971e-02, -3.8162e-01, -5.7424e-02],\n",
       "           [ 3.5127e-01, -6.4116e-01, -1.5713e-01],\n",
       "           [ 2.9980e-01, -3.1315e-01, -6.3450e-02],\n",
       "           [ 5.8217e-01, -3.5945e-03, -2.2688e-01],\n",
       "           [ 5.4688e-01,  1.3121e-01, -1.6104e-01],\n",
       "           [ 3.9860e-01,  3.5415e-01, -7.8997e-02],\n",
       "           [-1.7319e-01,  6.2045e-01,  2.3282e-02],\n",
       "           [ 5.4971e-02,  6.7549e-01,  2.7309e-02],\n",
       "           [ 5.8900e-02,  1.4162e-01, -1.8324e-02]],\n",
       "  \n",
       "          [[-3.1492e-01, -4.7672e-01, -2.2099e-01],\n",
       "           [-2.6671e-01, -1.9473e-01, -1.5360e-01],\n",
       "           [-3.4724e-02, -6.7312e-01, -1.7631e-01],\n",
       "           [-7.6606e-02, -3.3414e-01, -1.1500e-01],\n",
       "           [ 1.5707e-01, -7.4233e-01, -1.5428e-01],\n",
       "           [ 8.4993e-02, -3.8161e-01, -5.7131e-02],\n",
       "           [ 3.5142e-01, -6.4114e-01, -1.5679e-01],\n",
       "           [ 2.9988e-01, -3.1314e-01, -6.3131e-02],\n",
       "           [ 5.8216e-01, -3.4060e-03, -2.2679e-01],\n",
       "           [ 5.4691e-01,  1.3137e-01, -1.6086e-01],\n",
       "           [ 3.9862e-01,  3.5420e-01, -7.8681e-02],\n",
       "           [-1.7320e-01,  6.2044e-01,  2.3590e-02],\n",
       "           [ 5.4957e-02,  6.7549e-01,  2.7615e-02],\n",
       "           [ 5.8886e-02,  1.4162e-01, -1.8015e-02]],\n",
       "  \n",
       "          [[-3.2052e-01, -4.7961e-01, -2.1267e-01],\n",
       "           [-2.7502e-01, -1.9260e-01, -1.5059e-01],\n",
       "           [-4.3212e-02, -6.7310e-01, -1.7344e-01],\n",
       "           [-8.5189e-02, -3.3417e-01, -1.1192e-01],\n",
       "           [ 1.4846e-01, -7.4228e-01, -1.5163e-01],\n",
       "           [ 7.6337e-02, -3.8162e-01, -5.4105e-02],\n",
       "           [ 3.4278e-01, -6.4114e-01, -1.5374e-01],\n",
       "           [ 2.9122e-01, -3.1314e-01, -6.0068e-02],\n",
       "           [ 5.7311e-01, -3.3765e-03, -2.2379e-01],\n",
       "           [ 5.3818e-01,  1.3144e-01, -1.5777e-01],\n",
       "           [ 3.8995e-01,  3.5420e-01, -7.5607e-02],\n",
       "           [-1.8188e-01,  6.2045e-01,  2.6631e-02],\n",
       "           [ 4.6279e-02,  6.7549e-01,  3.0671e-02],\n",
       "           [ 5.0213e-02,  1.4161e-01, -1.4957e-02]],\n",
       "  \n",
       "          [[-3.2078e-01, -4.7963e-01, -2.1839e-01],\n",
       "           [-2.7512e-01, -1.9262e-01, -1.5651e-01],\n",
       "           [-4.3530e-02, -6.7320e-01, -1.7991e-01],\n",
       "           [-8.5246e-02, -3.3414e-01, -1.1769e-01],\n",
       "           [ 1.4858e-01, -7.4274e-01, -1.4641e-01],\n",
       "           [ 7.6562e-02, -3.8126e-01, -5.6241e-02],\n",
       "           [ 3.4270e-01, -6.4116e-01, -1.5987e-01],\n",
       "           [ 2.9118e-01, -3.1317e-01, -6.6144e-02],\n",
       "           [ 5.7299e-01, -3.5143e-03, -2.2956e-01],\n",
       "           [ 5.3816e-01,  1.3138e-01, -1.6364e-01],\n",
       "           [ 3.8997e-01,  3.5424e-01, -8.1734e-02],\n",
       "           [-1.8187e-01,  6.2044e-01,  2.0570e-02],\n",
       "           [ 4.6291e-02,  6.7548e-01,  2.4590e-02],\n",
       "           [ 5.0208e-02,  1.4160e-01, -2.1024e-02]],\n",
       "  \n",
       "          [[-3.1675e-01, -4.7859e-01, -2.1533e-01],\n",
       "           [-2.7224e-01, -1.8981e-01, -1.5620e-01],\n",
       "           [-3.9020e-02, -6.7189e-01, -1.7997e-01],\n",
       "           [-8.1377e-02, -3.3135e-01, -1.1809e-01],\n",
       "           [ 1.4540e-01, -7.4183e-01, -1.5481e-01],\n",
       "           [ 7.7300e-02, -3.7824e-01, -5.9905e-02],\n",
       "           [ 3.4770e-01, -6.3768e-01, -1.6903e-01],\n",
       "           [ 2.9667e-01, -3.0921e-01, -6.7396e-02],\n",
       "           [ 5.7821e-01,  3.9959e-03, -2.3525e-01],\n",
       "           [ 5.4329e-01,  1.3925e-01, -1.6871e-01],\n",
       "           [ 3.9451e-01,  3.6245e-01, -8.4970e-02],\n",
       "           [-1.7995e-01,  6.2709e-01,  2.1722e-02],\n",
       "           [ 4.8907e-02,  6.8296e-01,  2.4840e-02],\n",
       "           [ 5.3581e-02,  1.4694e-01, -2.1765e-02]],\n",
       "  \n",
       "          [[-3.1750e-01, -4.7803e-01, -2.1597e-01],\n",
       "           [-2.7259e-01, -1.8938e-01, -1.5615e-01],\n",
       "           [-3.9022e-02, -6.7196e-01, -1.7959e-01],\n",
       "           [-8.1376e-02, -3.3136e-01, -1.1805e-01],\n",
       "           [ 1.4541e-01, -7.4183e-01, -1.5473e-01],\n",
       "           [ 7.7291e-02, -3.7825e-01, -5.9830e-02],\n",
       "           [ 3.4443e-01, -6.3878e-01, -1.7043e-01],\n",
       "           [ 2.9489e-01, -3.1003e-01, -6.8481e-02],\n",
       "           [ 5.7790e-01,  4.0158e-03, -2.3521e-01],\n",
       "           [ 5.4324e-01,  1.3931e-01, -1.6862e-01],\n",
       "           [ 3.9453e-01,  3.6249e-01, -8.4891e-02],\n",
       "           [-1.7997e-01,  6.2710e-01,  2.1760e-02],\n",
       "           [ 4.8892e-02,  6.8296e-01,  2.4924e-02],\n",
       "           [ 5.3568e-02,  1.4694e-01, -2.1700e-02]],\n",
       "  \n",
       "          [[-3.1386e-01, -4.7411e-01, -2.0394e-01],\n",
       "           [-2.6978e-01, -1.8785e-01, -1.4462e-01],\n",
       "           [-3.8694e-02, -6.6610e-01, -1.6840e-01],\n",
       "           [-8.0551e-02, -3.2846e-01, -1.0642e-01],\n",
       "           [ 1.4925e-01, -7.3504e-01, -1.4293e-01],\n",
       "           [ 7.9610e-02, -3.7503e-01, -4.8341e-02],\n",
       "           [ 3.4174e-01, -6.3315e-01, -1.5863e-01],\n",
       "           [ 2.9253e-01, -3.0723e-01, -5.6840e-02],\n",
       "           [ 5.7322e-01,  4.1533e-03, -2.2311e-01],\n",
       "           [ 5.3879e-01,  1.3824e-01, -1.5650e-01],\n",
       "           [ 3.9125e-01,  3.5940e-01, -7.2878e-02],\n",
       "           [-1.7845e-01,  6.2161e-01,  3.3391e-02],\n",
       "           [ 4.8452e-02,  6.7699e-01,  3.6765e-02],\n",
       "           [ 5.3203e-02,  1.4568e-01, -1.0054e-02]],\n",
       "  \n",
       "          [[-3.1812e-01, -4.7205e-01, -2.0513e-01],\n",
       "           [-2.7474e-01, -1.8384e-01, -1.4903e-01],\n",
       "           [-4.3297e-02, -6.6473e-01, -1.7158e-01],\n",
       "           [-8.5310e-02, -3.2543e-01, -1.1101e-01],\n",
       "           [ 1.4824e-01, -7.3338e-01, -1.4601e-01],\n",
       "           [ 7.7124e-02, -3.7205e-01, -5.1713e-02],\n",
       "           [ 3.4273e-01, -6.3334e-01, -1.5201e-01],\n",
       "           [ 2.9023e-01, -3.0419e-01, -6.0283e-02],\n",
       "           [ 5.7303e-01,  9.0500e-03, -2.2271e-01],\n",
       "           [ 5.3837e-01,  1.4344e-01, -1.5590e-01],\n",
       "           [ 3.8967e-01,  3.6518e-01, -7.3068e-02],\n",
       "           [-1.8382e-01,  6.2899e-01,  2.8479e-02],\n",
       "           [ 4.4463e-02,  6.8416e-01,  3.4017e-02],\n",
       "           [ 4.9124e-02,  1.5083e-01, -1.4095e-02]],\n",
       "  \n",
       "          [[-3.1084e-01, -4.8036e-01, -2.1603e-01],\n",
       "           [-2.6681e-01, -1.9223e-01, -1.6005e-01],\n",
       "           [-3.4531e-02, -6.7342e-01, -1.8328e-01],\n",
       "           [-7.6533e-02, -3.3432e-01, -1.2133e-01],\n",
       "           [ 1.5710e-01, -7.4136e-01, -1.6241e-01],\n",
       "           [ 8.5540e-02, -3.8094e-01, -6.2197e-02],\n",
       "           [ 3.5129e-01, -6.4204e-01, -1.6747e-01],\n",
       "           [ 2.9877e-01, -3.1313e-01, -7.3837e-02],\n",
       "           [ 5.8176e-01,  2.5022e-04, -2.3396e-01],\n",
       "           [ 5.4704e-01,  1.3468e-01, -1.6724e-01],\n",
       "           [ 3.9829e-01,  3.5650e-01, -8.4578e-02],\n",
       "           [-1.7512e-01,  6.2010e-01,  1.7308e-02],\n",
       "           [ 5.3134e-02,  6.7528e-01,  2.2686e-02],\n",
       "           [ 5.7729e-02,  1.4195e-01, -2.5477e-02]]]),\n",
       "  tensor([[-133.2872,  -12.8680,  761.9981],\n",
       "          [-134.0469,  -13.1733,  764.2413],\n",
       "          [-134.1036,  -13.0756,  764.1958],\n",
       "          [-133.5309,  -12.9832,  763.7349],\n",
       "          [-133.3258,  -12.7867,  764.6445],\n",
       "          [-133.7862,  -12.6987,  764.6432],\n",
       "          [-134.0099,  -12.7558,  764.6301],\n",
       "          [-133.6220,  -12.6245,  762.9222],\n",
       "          [-133.6785,  -12.7303,  763.5060],\n",
       "          [-134.7840,  -13.0320,  765.1839]]),\n",
       "  tensor([[[  0.5517,   0.0000, -55.7241],\n",
       "           [  0.0000,   0.5517, -73.9310],\n",
       "           [  0.0000,   0.0000,   1.0000]],\n",
       "  \n",
       "          [[  0.5541,   0.0000, -55.9654],\n",
       "           [  0.0000,   0.5541, -74.8052],\n",
       "           [  0.0000,   0.0000,   1.0000]],\n",
       "  \n",
       "          [[  0.5541,   0.0000, -55.9654],\n",
       "           [  0.0000,   0.5541, -74.8052],\n",
       "           [  0.0000,   0.0000,   1.0000]],\n",
       "  \n",
       "          [[  0.5541,   0.0000, -56.5195],\n",
       "           [  0.0000,   0.5541, -74.8052],\n",
       "           [  0.0000,   0.0000,   1.0000]],\n",
       "  \n",
       "          [[  0.5541,   0.0000, -56.5195],\n",
       "           [  0.0000,   0.5541, -74.8052],\n",
       "           [  0.0000,   0.0000,   1.0000]],\n",
       "  \n",
       "          [[  0.5565,   0.0000, -56.7652],\n",
       "           [  0.0000,   0.5565, -75.1304],\n",
       "           [  0.0000,   0.0000,   1.0000]],\n",
       "  \n",
       "          [[  0.5565,   0.0000, -56.7652],\n",
       "           [  0.0000,   0.5565, -75.1304],\n",
       "           [  0.0000,   0.0000,   1.0000]],\n",
       "  \n",
       "          [[  0.5517,   0.0000, -55.7241],\n",
       "           [  0.0000,   0.5517, -73.9310],\n",
       "           [  0.0000,   0.0000,   1.0000]],\n",
       "  \n",
       "          [[  0.5541,   0.0000, -56.5195],\n",
       "           [  0.0000,   0.5541, -74.2511],\n",
       "           [  0.0000,   0.0000,   1.0000]],\n",
       "  \n",
       "          [[  0.5541,   0.0000, -55.9654],\n",
       "           [  0.0000,   0.5541, -74.8052],\n",
       "           [  0.0000,   0.0000,   1.0000]]]),\n",
       "  tensor([[300., 300., 300.],\n",
       "          [300., 300., 300.],\n",
       "          [300., 300., 300.],\n",
       "          [300., 300., 300.],\n",
       "          [300., 300., 300.],\n",
       "          [300., 300., 300.],\n",
       "          [300., 300., 300.],\n",
       "          [300., 300., 300.],\n",
       "          [300., 300., 300.],\n",
       "          [300., 300., 300.]])],\n",
       " tensor([[[-3.1785e-01, -4.7045e-01, -2.0619e-01],\n",
       "          [-2.6989e-01, -1.8959e-01, -1.3921e-01],\n",
       "          [-3.8962e-02, -6.6592e-01, -1.6169e-01],\n",
       "          [-8.0626e-02, -3.2838e-01, -1.0043e-01],\n",
       "          [ 1.5203e-01, -7.3496e-01, -1.3867e-01],\n",
       "          [ 8.0295e-02, -3.7566e-01, -4.2469e-02],\n",
       "          [ 3.4545e-01, -6.3409e-01, -1.4218e-01],\n",
       "          [ 2.9420e-01, -3.0749e-01, -4.8495e-02],\n",
       "          [ 5.7535e-01,  7.3123e-04, -2.1193e-01],\n",
       "          [ 5.4021e-01,  1.3496e-01, -1.4609e-01],\n",
       "          [ 3.9257e-01,  3.5693e-01, -6.4043e-02],\n",
       "          [-1.7675e-01,  6.2208e-01,  3.8236e-02],\n",
       "          [ 5.0424e-02,  6.7688e-01,  4.2264e-02],\n",
       "          [ 5.4335e-02,  1.4532e-01, -3.3700e-03]],\n",
       " \n",
       "         [[-3.1490e-01, -4.7682e-01, -2.2115e-01],\n",
       "          [-2.6673e-01, -1.9474e-01, -1.5417e-01],\n",
       "          [-3.4802e-02, -6.7313e-01, -1.7665e-01],\n",
       "          [-7.6647e-02, -3.3413e-01, -1.1539e-01],\n",
       "          [ 1.5702e-01, -7.4247e-01, -1.5363e-01],\n",
       "          [ 8.4971e-02, -3.8162e-01, -5.7424e-02],\n",
       "          [ 3.5127e-01, -6.4116e-01, -1.5713e-01],\n",
       "          [ 2.9980e-01, -3.1315e-01, -6.3450e-02],\n",
       "          [ 5.8217e-01, -3.5945e-03, -2.2688e-01],\n",
       "          [ 5.4688e-01,  1.3121e-01, -1.6104e-01],\n",
       "          [ 3.9860e-01,  3.5415e-01, -7.8997e-02],\n",
       "          [-1.7319e-01,  6.2045e-01,  2.3282e-02],\n",
       "          [ 5.4971e-02,  6.7549e-01,  2.7309e-02],\n",
       "          [ 5.8900e-02,  1.4162e-01, -1.8324e-02]],\n",
       " \n",
       "         [[-3.1492e-01, -4.7672e-01, -2.2099e-01],\n",
       "          [-2.6671e-01, -1.9473e-01, -1.5360e-01],\n",
       "          [-3.4724e-02, -6.7312e-01, -1.7631e-01],\n",
       "          [-7.6606e-02, -3.3414e-01, -1.1500e-01],\n",
       "          [ 1.5707e-01, -7.4233e-01, -1.5428e-01],\n",
       "          [ 8.4993e-02, -3.8161e-01, -5.7131e-02],\n",
       "          [ 3.5142e-01, -6.4114e-01, -1.5679e-01],\n",
       "          [ 2.9988e-01, -3.1314e-01, -6.3131e-02],\n",
       "          [ 5.8216e-01, -3.4060e-03, -2.2679e-01],\n",
       "          [ 5.4691e-01,  1.3137e-01, -1.6086e-01],\n",
       "          [ 3.9862e-01,  3.5420e-01, -7.8681e-02],\n",
       "          [-1.7320e-01,  6.2044e-01,  2.3590e-02],\n",
       "          [ 5.4957e-02,  6.7549e-01,  2.7615e-02],\n",
       "          [ 5.8886e-02,  1.4162e-01, -1.8015e-02]],\n",
       " \n",
       "         [[-3.2052e-01, -4.7961e-01, -2.1267e-01],\n",
       "          [-2.7502e-01, -1.9260e-01, -1.5059e-01],\n",
       "          [-4.3212e-02, -6.7310e-01, -1.7344e-01],\n",
       "          [-8.5189e-02, -3.3417e-01, -1.1192e-01],\n",
       "          [ 1.4846e-01, -7.4228e-01, -1.5163e-01],\n",
       "          [ 7.6337e-02, -3.8162e-01, -5.4105e-02],\n",
       "          [ 3.4278e-01, -6.4114e-01, -1.5374e-01],\n",
       "          [ 2.9122e-01, -3.1314e-01, -6.0068e-02],\n",
       "          [ 5.7311e-01, -3.3765e-03, -2.2379e-01],\n",
       "          [ 5.3818e-01,  1.3144e-01, -1.5777e-01],\n",
       "          [ 3.8995e-01,  3.5420e-01, -7.5607e-02],\n",
       "          [-1.8188e-01,  6.2045e-01,  2.6631e-02],\n",
       "          [ 4.6279e-02,  6.7549e-01,  3.0671e-02],\n",
       "          [ 5.0213e-02,  1.4161e-01, -1.4957e-02]],\n",
       " \n",
       "         [[-3.2078e-01, -4.7963e-01, -2.1839e-01],\n",
       "          [-2.7512e-01, -1.9262e-01, -1.5651e-01],\n",
       "          [-4.3530e-02, -6.7320e-01, -1.7991e-01],\n",
       "          [-8.5246e-02, -3.3414e-01, -1.1769e-01],\n",
       "          [ 1.4858e-01, -7.4274e-01, -1.4641e-01],\n",
       "          [ 7.6562e-02, -3.8126e-01, -5.6241e-02],\n",
       "          [ 3.4270e-01, -6.4116e-01, -1.5987e-01],\n",
       "          [ 2.9118e-01, -3.1317e-01, -6.6144e-02],\n",
       "          [ 5.7299e-01, -3.5143e-03, -2.2956e-01],\n",
       "          [ 5.3816e-01,  1.3138e-01, -1.6364e-01],\n",
       "          [ 3.8997e-01,  3.5424e-01, -8.1734e-02],\n",
       "          [-1.8187e-01,  6.2044e-01,  2.0570e-02],\n",
       "          [ 4.6291e-02,  6.7548e-01,  2.4590e-02],\n",
       "          [ 5.0208e-02,  1.4160e-01, -2.1024e-02]],\n",
       " \n",
       "         [[-3.1675e-01, -4.7859e-01, -2.1533e-01],\n",
       "          [-2.7224e-01, -1.8981e-01, -1.5620e-01],\n",
       "          [-3.9020e-02, -6.7189e-01, -1.7997e-01],\n",
       "          [-8.1377e-02, -3.3135e-01, -1.1809e-01],\n",
       "          [ 1.4540e-01, -7.4183e-01, -1.5481e-01],\n",
       "          [ 7.7300e-02, -3.7824e-01, -5.9905e-02],\n",
       "          [ 3.4770e-01, -6.3768e-01, -1.6903e-01],\n",
       "          [ 2.9667e-01, -3.0921e-01, -6.7396e-02],\n",
       "          [ 5.7821e-01,  3.9959e-03, -2.3525e-01],\n",
       "          [ 5.4329e-01,  1.3925e-01, -1.6871e-01],\n",
       "          [ 3.9451e-01,  3.6245e-01, -8.4970e-02],\n",
       "          [-1.7995e-01,  6.2709e-01,  2.1722e-02],\n",
       "          [ 4.8907e-02,  6.8296e-01,  2.4840e-02],\n",
       "          [ 5.3581e-02,  1.4694e-01, -2.1765e-02]],\n",
       " \n",
       "         [[-3.1750e-01, -4.7803e-01, -2.1597e-01],\n",
       "          [-2.7259e-01, -1.8938e-01, -1.5615e-01],\n",
       "          [-3.9022e-02, -6.7196e-01, -1.7959e-01],\n",
       "          [-8.1376e-02, -3.3136e-01, -1.1805e-01],\n",
       "          [ 1.4541e-01, -7.4183e-01, -1.5473e-01],\n",
       "          [ 7.7291e-02, -3.7825e-01, -5.9830e-02],\n",
       "          [ 3.4443e-01, -6.3878e-01, -1.7043e-01],\n",
       "          [ 2.9489e-01, -3.1003e-01, -6.8481e-02],\n",
       "          [ 5.7790e-01,  4.0158e-03, -2.3521e-01],\n",
       "          [ 5.4324e-01,  1.3931e-01, -1.6862e-01],\n",
       "          [ 3.9453e-01,  3.6249e-01, -8.4891e-02],\n",
       "          [-1.7997e-01,  6.2710e-01,  2.1760e-02],\n",
       "          [ 4.8892e-02,  6.8296e-01,  2.4924e-02],\n",
       "          [ 5.3568e-02,  1.4694e-01, -2.1700e-02]],\n",
       " \n",
       "         [[-3.1386e-01, -4.7411e-01, -2.0394e-01],\n",
       "          [-2.6978e-01, -1.8785e-01, -1.4462e-01],\n",
       "          [-3.8694e-02, -6.6610e-01, -1.6840e-01],\n",
       "          [-8.0551e-02, -3.2846e-01, -1.0642e-01],\n",
       "          [ 1.4925e-01, -7.3504e-01, -1.4293e-01],\n",
       "          [ 7.9610e-02, -3.7503e-01, -4.8341e-02],\n",
       "          [ 3.4174e-01, -6.3315e-01, -1.5863e-01],\n",
       "          [ 2.9253e-01, -3.0723e-01, -5.6840e-02],\n",
       "          [ 5.7322e-01,  4.1533e-03, -2.2311e-01],\n",
       "          [ 5.3879e-01,  1.3824e-01, -1.5650e-01],\n",
       "          [ 3.9125e-01,  3.5940e-01, -7.2878e-02],\n",
       "          [-1.7845e-01,  6.2161e-01,  3.3391e-02],\n",
       "          [ 4.8452e-02,  6.7699e-01,  3.6765e-02],\n",
       "          [ 5.3203e-02,  1.4568e-01, -1.0054e-02]],\n",
       " \n",
       "         [[-3.1812e-01, -4.7205e-01, -2.0513e-01],\n",
       "          [-2.7474e-01, -1.8384e-01, -1.4903e-01],\n",
       "          [-4.3297e-02, -6.6473e-01, -1.7158e-01],\n",
       "          [-8.5310e-02, -3.2543e-01, -1.1101e-01],\n",
       "          [ 1.4824e-01, -7.3338e-01, -1.4601e-01],\n",
       "          [ 7.7124e-02, -3.7205e-01, -5.1713e-02],\n",
       "          [ 3.4273e-01, -6.3334e-01, -1.5201e-01],\n",
       "          [ 2.9023e-01, -3.0419e-01, -6.0283e-02],\n",
       "          [ 5.7303e-01,  9.0500e-03, -2.2271e-01],\n",
       "          [ 5.3837e-01,  1.4344e-01, -1.5590e-01],\n",
       "          [ 3.8967e-01,  3.6518e-01, -7.3068e-02],\n",
       "          [-1.8382e-01,  6.2899e-01,  2.8479e-02],\n",
       "          [ 4.4463e-02,  6.8416e-01,  3.4017e-02],\n",
       "          [ 4.9124e-02,  1.5083e-01, -1.4095e-02]],\n",
       " \n",
       "         [[-3.1084e-01, -4.8036e-01, -2.1603e-01],\n",
       "          [-2.6681e-01, -1.9223e-01, -1.6005e-01],\n",
       "          [-3.4531e-02, -6.7342e-01, -1.8328e-01],\n",
       "          [-7.6533e-02, -3.3432e-01, -1.2133e-01],\n",
       "          [ 1.5710e-01, -7.4136e-01, -1.6241e-01],\n",
       "          [ 8.5540e-02, -3.8094e-01, -6.2197e-02],\n",
       "          [ 3.5129e-01, -6.4204e-01, -1.6747e-01],\n",
       "          [ 2.9877e-01, -3.1313e-01, -7.3837e-02],\n",
       "          [ 5.8176e-01,  2.5022e-04, -2.3396e-01],\n",
       "          [ 5.4704e-01,  1.3468e-01, -1.6724e-01],\n",
       "          [ 3.9829e-01,  3.5650e-01, -8.4578e-02],\n",
       "          [-1.7512e-01,  6.2010e-01,  1.7308e-02],\n",
       "          [ 5.3134e-02,  6.7528e-01,  2.2686e-02],\n",
       "          [ 5.7729e-02,  1.4195e-01, -2.5477e-02]]]),\n",
       " [[tensor([[[[150, 165, 170],\n",
       "             [150, 165, 170],\n",
       "             [150, 165, 170],\n",
       "             ...,\n",
       "             [144, 161, 167],\n",
       "             [141, 160, 167],\n",
       "             [139, 159, 166]],\n",
       "   \n",
       "            [[150, 165, 170],\n",
       "             [150, 165, 170],\n",
       "             [150, 165, 170],\n",
       "             ...,\n",
       "             [144, 161, 168],\n",
       "             [141, 160, 167],\n",
       "             [140, 160, 167]],\n",
       "   \n",
       "            [[150, 165, 170],\n",
       "             [150, 165, 170],\n",
       "             [150, 165, 170],\n",
       "             ...,\n",
       "             [144, 160, 167],\n",
       "             [141, 160, 167],\n",
       "             [140, 160, 167]],\n",
       "   \n",
       "            ...,\n",
       "   \n",
       "            [[103, 103, 103],\n",
       "             [106, 106, 106],\n",
       "             [109, 109, 109],\n",
       "             ...,\n",
       "             [120, 121, 115],\n",
       "             [113, 114, 108],\n",
       "             [103, 104,  98]],\n",
       "   \n",
       "            [[100, 100, 100],\n",
       "             [101, 101, 101],\n",
       "             [101, 101, 101],\n",
       "             ...,\n",
       "             [117, 118, 112],\n",
       "             [108, 109, 103],\n",
       "             [ 96,  98,  92]],\n",
       "   \n",
       "            [[103, 103, 103],\n",
       "             [101, 101, 101],\n",
       "             [ 98,  98,  98],\n",
       "             ...,\n",
       "             [117, 118, 112],\n",
       "             [108, 109, 103],\n",
       "             [ 98,  99,  93]]],\n",
       "   \n",
       "   \n",
       "           [[[150, 165, 170],\n",
       "             [150, 165, 170],\n",
       "             [150, 165, 170],\n",
       "             ...,\n",
       "             [144, 161, 167],\n",
       "             [141, 160, 167],\n",
       "             [139, 159, 166]],\n",
       "   \n",
       "            [[150, 165, 170],\n",
       "             [150, 165, 170],\n",
       "             [150, 165, 170],\n",
       "             ...,\n",
       "             [144, 161, 168],\n",
       "             [141, 160, 167],\n",
       "             [140, 160, 167]],\n",
       "   \n",
       "            [[150, 165, 170],\n",
       "             [150, 165, 170],\n",
       "             [150, 165, 170],\n",
       "             ...,\n",
       "             [144, 160, 167],\n",
       "             [141, 160, 167],\n",
       "             [140, 160, 167]],\n",
       "   \n",
       "            ...,\n",
       "   \n",
       "            [[103, 103, 103],\n",
       "             [106, 106, 106],\n",
       "             [109, 109, 109],\n",
       "             ...,\n",
       "             [120, 121, 115],\n",
       "             [113, 114, 108],\n",
       "             [103, 104,  98]],\n",
       "   \n",
       "            [[100, 100, 100],\n",
       "             [101, 101, 101],\n",
       "             [101, 101, 101],\n",
       "             ...,\n",
       "             [117, 118, 112],\n",
       "             [108, 109, 103],\n",
       "             [ 96,  98,  92]],\n",
       "   \n",
       "            [[103, 103, 103],\n",
       "             [101, 101, 101],\n",
       "             [ 98,  98,  98],\n",
       "             ...,\n",
       "             [117, 118, 112],\n",
       "             [108, 109, 103],\n",
       "             [ 98,  99,  93]]],\n",
       "   \n",
       "   \n",
       "           [[[150, 165, 170],\n",
       "             [150, 165, 170],\n",
       "             [150, 165, 170],\n",
       "             ...,\n",
       "             [144, 161, 167],\n",
       "             [141, 160, 167],\n",
       "             [139, 159, 166]],\n",
       "   \n",
       "            [[150, 165, 170],\n",
       "             [150, 165, 170],\n",
       "             [150, 165, 170],\n",
       "             ...,\n",
       "             [144, 161, 168],\n",
       "             [141, 160, 167],\n",
       "             [140, 160, 167]],\n",
       "   \n",
       "            [[150, 165, 170],\n",
       "             [150, 165, 170],\n",
       "             [150, 165, 170],\n",
       "             ...,\n",
       "             [144, 160, 167],\n",
       "             [141, 160, 167],\n",
       "             [140, 160, 167]],\n",
       "   \n",
       "            ...,\n",
       "   \n",
       "            [[103, 103, 103],\n",
       "             [106, 106, 106],\n",
       "             [109, 109, 109],\n",
       "             ...,\n",
       "             [120, 121, 115],\n",
       "             [113, 114, 108],\n",
       "             [103, 104,  98]],\n",
       "   \n",
       "            [[100, 100, 100],\n",
       "             [101, 101, 101],\n",
       "             [101, 101, 101],\n",
       "             ...,\n",
       "             [117, 118, 112],\n",
       "             [108, 109, 103],\n",
       "             [ 96,  98,  92]],\n",
       "   \n",
       "            [[103, 103, 103],\n",
       "             [101, 101, 101],\n",
       "             [ 98,  98,  98],\n",
       "             ...,\n",
       "             [117, 118, 112],\n",
       "             [108, 109, 103],\n",
       "             [ 98,  99,  93]]],\n",
       "   \n",
       "   \n",
       "           ...,\n",
       "   \n",
       "   \n",
       "           [[[150, 165, 170],\n",
       "             [150, 165, 170],\n",
       "             [150, 165, 170],\n",
       "             ...,\n",
       "             [144, 161, 167],\n",
       "             [141, 160, 167],\n",
       "             [139, 159, 166]],\n",
       "   \n",
       "            [[150, 165, 170],\n",
       "             [150, 165, 170],\n",
       "             [150, 165, 170],\n",
       "             ...,\n",
       "             [144, 161, 168],\n",
       "             [141, 160, 167],\n",
       "             [140, 160, 167]],\n",
       "   \n",
       "            [[150, 165, 170],\n",
       "             [150, 165, 170],\n",
       "             [150, 165, 170],\n",
       "             ...,\n",
       "             [144, 160, 167],\n",
       "             [141, 160, 167],\n",
       "             [140, 160, 167]],\n",
       "   \n",
       "            ...,\n",
       "   \n",
       "            [[103, 103, 103],\n",
       "             [106, 106, 106],\n",
       "             [109, 109, 109],\n",
       "             ...,\n",
       "             [120, 121, 115],\n",
       "             [113, 114, 108],\n",
       "             [103, 104,  98]],\n",
       "   \n",
       "            [[100, 100, 100],\n",
       "             [101, 101, 101],\n",
       "             [101, 101, 101],\n",
       "             ...,\n",
       "             [117, 118, 112],\n",
       "             [108, 109, 103],\n",
       "             [ 96,  98,  92]],\n",
       "   \n",
       "            [[103, 103, 103],\n",
       "             [101, 101, 101],\n",
       "             [ 98,  98,  98],\n",
       "             ...,\n",
       "             [117, 118, 112],\n",
       "             [108, 109, 103],\n",
       "             [ 98,  99,  93]]],\n",
       "   \n",
       "   \n",
       "           [[[150, 165, 170],\n",
       "             [150, 165, 170],\n",
       "             [150, 165, 170],\n",
       "             ...,\n",
       "             [144, 161, 167],\n",
       "             [141, 160, 167],\n",
       "             [139, 159, 166]],\n",
       "   \n",
       "            [[150, 165, 170],\n",
       "             [150, 165, 170],\n",
       "             [150, 165, 170],\n",
       "             ...,\n",
       "             [144, 161, 168],\n",
       "             [141, 160, 167],\n",
       "             [140, 160, 167]],\n",
       "   \n",
       "            [[150, 165, 170],\n",
       "             [150, 165, 170],\n",
       "             [150, 165, 170],\n",
       "             ...,\n",
       "             [144, 160, 167],\n",
       "             [141, 160, 167],\n",
       "             [140, 160, 167]],\n",
       "   \n",
       "            ...,\n",
       "   \n",
       "            [[103, 103, 103],\n",
       "             [106, 106, 106],\n",
       "             [109, 109, 109],\n",
       "             ...,\n",
       "             [120, 121, 115],\n",
       "             [113, 114, 108],\n",
       "             [103, 104,  98]],\n",
       "   \n",
       "            [[100, 100, 100],\n",
       "             [101, 101, 101],\n",
       "             [101, 101, 101],\n",
       "             ...,\n",
       "             [117, 118, 112],\n",
       "             [108, 109, 103],\n",
       "             [ 96,  98,  92]],\n",
       "   \n",
       "            [[103, 103, 103],\n",
       "             [101, 101, 101],\n",
       "             [ 98,  98,  98],\n",
       "             ...,\n",
       "             [117, 118, 112],\n",
       "             [108, 109, 103],\n",
       "             [ 98,  99,  93]]],\n",
       "   \n",
       "   \n",
       "           [[[150, 165, 170],\n",
       "             [150, 165, 170],\n",
       "             [150, 165, 170],\n",
       "             ...,\n",
       "             [144, 161, 167],\n",
       "             [141, 160, 167],\n",
       "             [139, 159, 166]],\n",
       "   \n",
       "            [[150, 165, 170],\n",
       "             [150, 165, 170],\n",
       "             [150, 165, 170],\n",
       "             ...,\n",
       "             [144, 161, 168],\n",
       "             [141, 160, 167],\n",
       "             [140, 160, 167]],\n",
       "   \n",
       "            [[150, 165, 170],\n",
       "             [150, 165, 170],\n",
       "             [150, 165, 170],\n",
       "             ...,\n",
       "             [144, 160, 167],\n",
       "             [141, 160, 167],\n",
       "             [140, 160, 167]],\n",
       "   \n",
       "            ...,\n",
       "   \n",
       "            [[103, 103, 103],\n",
       "             [106, 106, 106],\n",
       "             [109, 109, 109],\n",
       "             ...,\n",
       "             [120, 121, 115],\n",
       "             [113, 114, 108],\n",
       "             [103, 104,  98]],\n",
       "   \n",
       "            [[100, 100, 100],\n",
       "             [101, 101, 101],\n",
       "             [101, 101, 101],\n",
       "             ...,\n",
       "             [117, 118, 112],\n",
       "             [108, 109, 103],\n",
       "             [ 96,  98,  92]],\n",
       "   \n",
       "            [[103, 103, 103],\n",
       "             [101, 101, 101],\n",
       "             [ 98,  98,  98],\n",
       "             ...,\n",
       "             [117, 118, 112],\n",
       "             [108, 109, 103],\n",
       "             [ 98,  99,  93]]]], dtype=torch.uint8),\n",
       "   tensor([[[[ 0.0882,  0.0882,  0.0882,  ...,  0.0647,  0.0529,  0.0451],\n",
       "             [ 0.0882,  0.0882,  0.0882,  ...,  0.0647,  0.0529,  0.0490],\n",
       "             [ 0.0882,  0.0882,  0.0882,  ...,  0.0647,  0.0529,  0.0490],\n",
       "             ...,\n",
       "             [-0.0961, -0.0843, -0.0725,  ..., -0.0294, -0.0569, -0.0961],\n",
       "             [-0.1078, -0.1039, -0.1039,  ..., -0.0412, -0.0765, -0.1235],\n",
       "             [-0.0961, -0.1039, -0.1157,  ..., -0.0412, -0.0765, -0.1157]],\n",
       "   \n",
       "            [[ 0.1471,  0.1471,  0.1471,  ...,  0.1314,  0.1275,  0.1235],\n",
       "             [ 0.1471,  0.1471,  0.1471,  ...,  0.1314,  0.1275,  0.1275],\n",
       "             [ 0.1471,  0.1471,  0.1471,  ...,  0.1275,  0.1275,  0.1275],\n",
       "             ...,\n",
       "             [-0.0961, -0.0843, -0.0725,  ..., -0.0255, -0.0529, -0.0922],\n",
       "             [-0.1078, -0.1039, -0.1039,  ..., -0.0373, -0.0725, -0.1157],\n",
       "             [-0.0961, -0.1039, -0.1157,  ..., -0.0373, -0.0725, -0.1118]],\n",
       "   \n",
       "            [[ 0.1667,  0.1667,  0.1667,  ...,  0.1549,  0.1549,  0.1510],\n",
       "             [ 0.1667,  0.1667,  0.1667,  ...,  0.1588,  0.1549,  0.1549],\n",
       "             [ 0.1667,  0.1667,  0.1667,  ...,  0.1549,  0.1549,  0.1549],\n",
       "             ...,\n",
       "             [-0.0961, -0.0843, -0.0725,  ..., -0.0490, -0.0765, -0.1157],\n",
       "             [-0.1078, -0.1039, -0.1039,  ..., -0.0608, -0.0961, -0.1392],\n",
       "             [-0.0961, -0.1039, -0.1157,  ..., -0.0608, -0.0961, -0.1353]]],\n",
       "   \n",
       "   \n",
       "           [[[ 0.0882,  0.0882,  0.0882,  ...,  0.0647,  0.0529,  0.0451],\n",
       "             [ 0.0882,  0.0882,  0.0882,  ...,  0.0647,  0.0529,  0.0490],\n",
       "             [ 0.0882,  0.0882,  0.0882,  ...,  0.0647,  0.0529,  0.0490],\n",
       "             ...,\n",
       "             [-0.0961, -0.0843, -0.0725,  ..., -0.0294, -0.0569, -0.0961],\n",
       "             [-0.1078, -0.1039, -0.1039,  ..., -0.0412, -0.0765, -0.1235],\n",
       "             [-0.0961, -0.1039, -0.1157,  ..., -0.0412, -0.0765, -0.1157]],\n",
       "   \n",
       "            [[ 0.1471,  0.1471,  0.1471,  ...,  0.1314,  0.1275,  0.1235],\n",
       "             [ 0.1471,  0.1471,  0.1471,  ...,  0.1314,  0.1275,  0.1275],\n",
       "             [ 0.1471,  0.1471,  0.1471,  ...,  0.1275,  0.1275,  0.1275],\n",
       "             ...,\n",
       "             [-0.0961, -0.0843, -0.0725,  ..., -0.0255, -0.0529, -0.0922],\n",
       "             [-0.1078, -0.1039, -0.1039,  ..., -0.0373, -0.0725, -0.1157],\n",
       "             [-0.0961, -0.1039, -0.1157,  ..., -0.0373, -0.0725, -0.1118]],\n",
       "   \n",
       "            [[ 0.1667,  0.1667,  0.1667,  ...,  0.1549,  0.1549,  0.1510],\n",
       "             [ 0.1667,  0.1667,  0.1667,  ...,  0.1588,  0.1549,  0.1549],\n",
       "             [ 0.1667,  0.1667,  0.1667,  ...,  0.1549,  0.1549,  0.1549],\n",
       "             ...,\n",
       "             [-0.0961, -0.0843, -0.0725,  ..., -0.0490, -0.0765, -0.1157],\n",
       "             [-0.1078, -0.1039, -0.1039,  ..., -0.0608, -0.0961, -0.1392],\n",
       "             [-0.0961, -0.1039, -0.1157,  ..., -0.0608, -0.0961, -0.1353]]],\n",
       "   \n",
       "   \n",
       "           [[[ 0.0882,  0.0882,  0.0882,  ...,  0.0647,  0.0529,  0.0451],\n",
       "             [ 0.0882,  0.0882,  0.0882,  ...,  0.0647,  0.0529,  0.0490],\n",
       "             [ 0.0882,  0.0882,  0.0882,  ...,  0.0647,  0.0529,  0.0490],\n",
       "             ...,\n",
       "             [-0.0961, -0.0843, -0.0725,  ..., -0.0294, -0.0569, -0.0961],\n",
       "             [-0.1078, -0.1039, -0.1039,  ..., -0.0412, -0.0765, -0.1235],\n",
       "             [-0.0961, -0.1039, -0.1157,  ..., -0.0412, -0.0765, -0.1157]],\n",
       "   \n",
       "            [[ 0.1471,  0.1471,  0.1471,  ...,  0.1314,  0.1275,  0.1235],\n",
       "             [ 0.1471,  0.1471,  0.1471,  ...,  0.1314,  0.1275,  0.1275],\n",
       "             [ 0.1471,  0.1471,  0.1471,  ...,  0.1275,  0.1275,  0.1275],\n",
       "             ...,\n",
       "             [-0.0961, -0.0843, -0.0725,  ..., -0.0255, -0.0529, -0.0922],\n",
       "             [-0.1078, -0.1039, -0.1039,  ..., -0.0373, -0.0725, -0.1157],\n",
       "             [-0.0961, -0.1039, -0.1157,  ..., -0.0373, -0.0725, -0.1118]],\n",
       "   \n",
       "            [[ 0.1667,  0.1667,  0.1667,  ...,  0.1549,  0.1549,  0.1510],\n",
       "             [ 0.1667,  0.1667,  0.1667,  ...,  0.1588,  0.1549,  0.1549],\n",
       "             [ 0.1667,  0.1667,  0.1667,  ...,  0.1549,  0.1549,  0.1549],\n",
       "             ...,\n",
       "             [-0.0961, -0.0843, -0.0725,  ..., -0.0490, -0.0765, -0.1157],\n",
       "             [-0.1078, -0.1039, -0.1039,  ..., -0.0608, -0.0961, -0.1392],\n",
       "             [-0.0961, -0.1039, -0.1157,  ..., -0.0608, -0.0961, -0.1353]]],\n",
       "   \n",
       "   \n",
       "           ...,\n",
       "   \n",
       "   \n",
       "           [[[ 0.0882,  0.0882,  0.0882,  ...,  0.0647,  0.0529,  0.0451],\n",
       "             [ 0.0882,  0.0882,  0.0882,  ...,  0.0647,  0.0529,  0.0490],\n",
       "             [ 0.0882,  0.0882,  0.0882,  ...,  0.0647,  0.0529,  0.0490],\n",
       "             ...,\n",
       "             [-0.0961, -0.0843, -0.0725,  ..., -0.0294, -0.0569, -0.0961],\n",
       "             [-0.1078, -0.1039, -0.1039,  ..., -0.0412, -0.0765, -0.1235],\n",
       "             [-0.0961, -0.1039, -0.1157,  ..., -0.0412, -0.0765, -0.1157]],\n",
       "   \n",
       "            [[ 0.1471,  0.1471,  0.1471,  ...,  0.1314,  0.1275,  0.1235],\n",
       "             [ 0.1471,  0.1471,  0.1471,  ...,  0.1314,  0.1275,  0.1275],\n",
       "             [ 0.1471,  0.1471,  0.1471,  ...,  0.1275,  0.1275,  0.1275],\n",
       "             ...,\n",
       "             [-0.0961, -0.0843, -0.0725,  ..., -0.0255, -0.0529, -0.0922],\n",
       "             [-0.1078, -0.1039, -0.1039,  ..., -0.0373, -0.0725, -0.1157],\n",
       "             [-0.0961, -0.1039, -0.1157,  ..., -0.0373, -0.0725, -0.1118]],\n",
       "   \n",
       "            [[ 0.1667,  0.1667,  0.1667,  ...,  0.1549,  0.1549,  0.1510],\n",
       "             [ 0.1667,  0.1667,  0.1667,  ...,  0.1588,  0.1549,  0.1549],\n",
       "             [ 0.1667,  0.1667,  0.1667,  ...,  0.1549,  0.1549,  0.1549],\n",
       "             ...,\n",
       "             [-0.0961, -0.0843, -0.0725,  ..., -0.0490, -0.0765, -0.1157],\n",
       "             [-0.1078, -0.1039, -0.1039,  ..., -0.0608, -0.0961, -0.1392],\n",
       "             [-0.0961, -0.1039, -0.1157,  ..., -0.0608, -0.0961, -0.1353]]],\n",
       "   \n",
       "   \n",
       "           [[[ 0.0882,  0.0882,  0.0882,  ...,  0.0647,  0.0529,  0.0451],\n",
       "             [ 0.0882,  0.0882,  0.0882,  ...,  0.0647,  0.0529,  0.0490],\n",
       "             [ 0.0882,  0.0882,  0.0882,  ...,  0.0647,  0.0529,  0.0490],\n",
       "             ...,\n",
       "             [-0.0961, -0.0843, -0.0725,  ..., -0.0294, -0.0569, -0.0961],\n",
       "             [-0.1078, -0.1039, -0.1039,  ..., -0.0412, -0.0765, -0.1235],\n",
       "             [-0.0961, -0.1039, -0.1157,  ..., -0.0412, -0.0765, -0.1157]],\n",
       "   \n",
       "            [[ 0.1471,  0.1471,  0.1471,  ...,  0.1314,  0.1275,  0.1235],\n",
       "             [ 0.1471,  0.1471,  0.1471,  ...,  0.1314,  0.1275,  0.1275],\n",
       "             [ 0.1471,  0.1471,  0.1471,  ...,  0.1275,  0.1275,  0.1275],\n",
       "             ...,\n",
       "             [-0.0961, -0.0843, -0.0725,  ..., -0.0255, -0.0529, -0.0922],\n",
       "             [-0.1078, -0.1039, -0.1039,  ..., -0.0373, -0.0725, -0.1157],\n",
       "             [-0.0961, -0.1039, -0.1157,  ..., -0.0373, -0.0725, -0.1118]],\n",
       "   \n",
       "            [[ 0.1667,  0.1667,  0.1667,  ...,  0.1549,  0.1549,  0.1510],\n",
       "             [ 0.1667,  0.1667,  0.1667,  ...,  0.1588,  0.1549,  0.1549],\n",
       "             [ 0.1667,  0.1667,  0.1667,  ...,  0.1549,  0.1549,  0.1549],\n",
       "             ...,\n",
       "             [-0.0961, -0.0843, -0.0725,  ..., -0.0490, -0.0765, -0.1157],\n",
       "             [-0.1078, -0.1039, -0.1039,  ..., -0.0608, -0.0961, -0.1392],\n",
       "             [-0.0961, -0.1039, -0.1157,  ..., -0.0608, -0.0961, -0.1353]]],\n",
       "   \n",
       "   \n",
       "           [[[ 0.0882,  0.0882,  0.0882,  ...,  0.0647,  0.0529,  0.0451],\n",
       "             [ 0.0882,  0.0882,  0.0882,  ...,  0.0647,  0.0529,  0.0490],\n",
       "             [ 0.0882,  0.0882,  0.0882,  ...,  0.0647,  0.0529,  0.0490],\n",
       "             ...,\n",
       "             [-0.0961, -0.0843, -0.0725,  ..., -0.0294, -0.0569, -0.0961],\n",
       "             [-0.1078, -0.1039, -0.1039,  ..., -0.0412, -0.0765, -0.1235],\n",
       "             [-0.0961, -0.1039, -0.1157,  ..., -0.0412, -0.0765, -0.1157]],\n",
       "   \n",
       "            [[ 0.1471,  0.1471,  0.1471,  ...,  0.1314,  0.1275,  0.1235],\n",
       "             [ 0.1471,  0.1471,  0.1471,  ...,  0.1314,  0.1275,  0.1275],\n",
       "             [ 0.1471,  0.1471,  0.1471,  ...,  0.1275,  0.1275,  0.1275],\n",
       "             ...,\n",
       "             [-0.0961, -0.0843, -0.0725,  ..., -0.0255, -0.0529, -0.0922],\n",
       "             [-0.1078, -0.1039, -0.1039,  ..., -0.0373, -0.0725, -0.1157],\n",
       "             [-0.0961, -0.1039, -0.1157,  ..., -0.0373, -0.0725, -0.1118]],\n",
       "   \n",
       "            [[ 0.1667,  0.1667,  0.1667,  ...,  0.1549,  0.1549,  0.1510],\n",
       "             [ 0.1667,  0.1667,  0.1667,  ...,  0.1588,  0.1549,  0.1549],\n",
       "             [ 0.1667,  0.1667,  0.1667,  ...,  0.1549,  0.1549,  0.1549],\n",
       "             ...,\n",
       "             [-0.0961, -0.0843, -0.0725,  ..., -0.0490, -0.0765, -0.1157],\n",
       "             [-0.1078, -0.1039, -0.1039,  ..., -0.0608, -0.0961, -0.1392],\n",
       "             [-0.0961, -0.1039, -0.1157,  ..., -0.0608, -0.0961, -0.1353]]]]),\n",
       "   tensor([[[213.2000,   0.0000, 128.0000],\n",
       "            [  0.0000, 213.2000, 128.0000],\n",
       "            [  0.0000,   0.0000,   1.0000]],\n",
       "   \n",
       "           [[213.2000,   0.0000, 128.0000],\n",
       "            [  0.0000, 213.2000, 128.0000],\n",
       "            [  0.0000,   0.0000,   1.0000]],\n",
       "   \n",
       "           [[213.2000,   0.0000, 128.0000],\n",
       "            [  0.0000, 213.2000, 128.0000],\n",
       "            [  0.0000,   0.0000,   1.0000]],\n",
       "   \n",
       "           [[213.2000,   0.0000, 128.0000],\n",
       "            [  0.0000, 213.2000, 128.0000],\n",
       "            [  0.0000,   0.0000,   1.0000]],\n",
       "   \n",
       "           [[213.2000,   0.0000, 128.0000],\n",
       "            [  0.0000, 213.2000, 128.0000],\n",
       "            [  0.0000,   0.0000,   1.0000]],\n",
       "   \n",
       "           [[213.2000,   0.0000, 128.0000],\n",
       "            [  0.0000, 213.2000, 128.0000],\n",
       "            [  0.0000,   0.0000,   1.0000]],\n",
       "   \n",
       "           [[213.2000,   0.0000, 128.0000],\n",
       "            [  0.0000, 213.2000, 128.0000],\n",
       "            [  0.0000,   0.0000,   1.0000]],\n",
       "   \n",
       "           [[213.2000,   0.0000, 128.0000],\n",
       "            [  0.0000, 213.2000, 128.0000],\n",
       "            [  0.0000,   0.0000,   1.0000]],\n",
       "   \n",
       "           [[213.2000,   0.0000, 128.0000],\n",
       "            [  0.0000, 213.2000, 128.0000],\n",
       "            [  0.0000,   0.0000,   1.0000]],\n",
       "   \n",
       "           [[213.2000,   0.0000, 128.0000],\n",
       "            [  0.0000, 213.2000, 128.0000],\n",
       "            [  0.0000,   0.0000,   1.0000]]])],\n",
       "  {'K': tensor([[[266.5000,   0.0000, 160.0000],\n",
       "            [  0.0000, 266.5000, 160.0000],\n",
       "            [  0.0000,   0.0000,   1.0000]],\n",
       "   \n",
       "           [[266.5000,   0.0000, 160.0000],\n",
       "            [  0.0000, 266.5000, 160.0000],\n",
       "            [  0.0000,   0.0000,   1.0000]],\n",
       "   \n",
       "           [[266.5000,   0.0000, 160.0000],\n",
       "            [  0.0000, 266.5000, 160.0000],\n",
       "            [  0.0000,   0.0000,   1.0000]],\n",
       "   \n",
       "           [[266.5000,   0.0000, 160.0000],\n",
       "            [  0.0000, 266.5000, 160.0000],\n",
       "            [  0.0000,   0.0000,   1.0000]],\n",
       "   \n",
       "           [[266.5000,   0.0000, 160.0000],\n",
       "            [  0.0000, 266.5000, 160.0000],\n",
       "            [  0.0000,   0.0000,   1.0000]],\n",
       "   \n",
       "           [[266.5000,   0.0000, 160.0000],\n",
       "            [  0.0000, 266.5000, 160.0000],\n",
       "            [  0.0000,   0.0000,   1.0000]],\n",
       "   \n",
       "           [[266.5000,   0.0000, 160.0000],\n",
       "            [  0.0000, 266.5000, 160.0000],\n",
       "            [  0.0000,   0.0000,   1.0000]],\n",
       "   \n",
       "           [[266.5000,   0.0000, 160.0000],\n",
       "            [  0.0000, 266.5000, 160.0000],\n",
       "            [  0.0000,   0.0000,   1.0000]],\n",
       "   \n",
       "           [[266.5000,   0.0000, 160.0000],\n",
       "            [  0.0000, 266.5000, 160.0000],\n",
       "            [  0.0000,   0.0000,   1.0000]],\n",
       "   \n",
       "           [[266.5000,   0.0000, 160.0000],\n",
       "            [  0.0000, 266.5000, 160.0000],\n",
       "            [  0.0000,   0.0000,   1.0000]]]),\n",
       "   'xyz': tensor([[[ 0.2719,  0.1191,  0.1520],\n",
       "            [ 0.2187,  0.2133,  0.0981],\n",
       "            [ 0.2259,  0.1978,  0.1129],\n",
       "            ...,\n",
       "            [-0.0032, -0.0432,  0.3502],\n",
       "            [ 0.0102, -0.0521,  0.3527],\n",
       "            [-0.0043, -0.0646,  0.3694]],\n",
       "   \n",
       "           [[ 0.2719,  0.1191,  0.1520],\n",
       "            [ 0.2187,  0.2133,  0.0981],\n",
       "            [ 0.2259,  0.1978,  0.1129],\n",
       "            ...,\n",
       "            [-0.0032, -0.0432,  0.3502],\n",
       "            [ 0.0102, -0.0521,  0.3527],\n",
       "            [-0.0043, -0.0646,  0.3694]],\n",
       "   \n",
       "           [[ 0.2719,  0.1191,  0.1520],\n",
       "            [ 0.2187,  0.2133,  0.0981],\n",
       "            [ 0.2259,  0.1978,  0.1129],\n",
       "            ...,\n",
       "            [-0.0032, -0.0432,  0.3502],\n",
       "            [ 0.0102, -0.0521,  0.3527],\n",
       "            [-0.0043, -0.0646,  0.3694]],\n",
       "   \n",
       "           ...,\n",
       "   \n",
       "           [[ 0.2719,  0.1191,  0.1520],\n",
       "            [ 0.2187,  0.2133,  0.0981],\n",
       "            [ 0.2259,  0.1978,  0.1129],\n",
       "            ...,\n",
       "            [-0.0032, -0.0432,  0.3502],\n",
       "            [ 0.0102, -0.0521,  0.3527],\n",
       "            [-0.0043, -0.0646,  0.3694]],\n",
       "   \n",
       "           [[ 0.2719,  0.1191,  0.1520],\n",
       "            [ 0.2187,  0.2133,  0.0981],\n",
       "            [ 0.2259,  0.1978,  0.1129],\n",
       "            ...,\n",
       "            [-0.0032, -0.0432,  0.3502],\n",
       "            [ 0.0102, -0.0521,  0.3527],\n",
       "            [-0.0043, -0.0646,  0.3694]],\n",
       "   \n",
       "           [[ 0.2719,  0.1191,  0.1520],\n",
       "            [ 0.2187,  0.2133,  0.0981],\n",
       "            [ 0.2259,  0.1978,  0.1129],\n",
       "            ...,\n",
       "            [-0.0032, -0.0432,  0.3502],\n",
       "            [ 0.0102, -0.0521,  0.3527],\n",
       "            [-0.0043, -0.0646,  0.3694]]]),\n",
       "   'uv_vis': tensor([[[636.7000, 368.9000,   0.0000],\n",
       "            [754.3000, 739.5000,   0.0000],\n",
       "            [693.3000, 627.1000,   0.0000],\n",
       "            ...,\n",
       "            [157.6000, 127.1000,   1.0000],\n",
       "            [167.7000, 120.6000,   1.0000],\n",
       "            [156.9000, 113.4000,   1.0000]],\n",
       "   \n",
       "           [[636.7000, 368.9000,   0.0000],\n",
       "            [754.3000, 739.5000,   0.0000],\n",
       "            [693.3000, 627.1000,   0.0000],\n",
       "            ...,\n",
       "            [157.6000, 127.1000,   1.0000],\n",
       "            [167.7000, 120.6000,   1.0000],\n",
       "            [156.9000, 113.4000,   1.0000]],\n",
       "   \n",
       "           [[636.7000, 368.9000,   0.0000],\n",
       "            [754.3000, 739.5000,   0.0000],\n",
       "            [693.3000, 627.1000,   0.0000],\n",
       "            ...,\n",
       "            [157.6000, 127.1000,   1.0000],\n",
       "            [167.7000, 120.6000,   1.0000],\n",
       "            [156.9000, 113.4000,   1.0000]],\n",
       "   \n",
       "           ...,\n",
       "   \n",
       "           [[636.7000, 368.9000,   0.0000],\n",
       "            [754.3000, 739.5000,   0.0000],\n",
       "            [693.3000, 627.1000,   0.0000],\n",
       "            ...,\n",
       "            [157.6000, 127.1000,   1.0000],\n",
       "            [167.7000, 120.6000,   1.0000],\n",
       "            [156.9000, 113.4000,   1.0000]],\n",
       "   \n",
       "           [[636.7000, 368.9000,   0.0000],\n",
       "            [754.3000, 739.5000,   0.0000],\n",
       "            [693.3000, 627.1000,   0.0000],\n",
       "            ...,\n",
       "            [157.6000, 127.1000,   1.0000],\n",
       "            [167.7000, 120.6000,   1.0000],\n",
       "            [156.9000, 113.4000,   1.0000]],\n",
       "   \n",
       "           [[636.7000, 368.9000,   0.0000],\n",
       "            [754.3000, 739.5000,   0.0000],\n",
       "            [693.3000, 627.1000,   0.0000],\n",
       "            ...,\n",
       "            [157.6000, 127.1000,   1.0000],\n",
       "            [167.7000, 120.6000,   1.0000],\n",
       "            [156.9000, 113.4000,   1.0000]]])}],\n",
       " tensor([[[ 0.2719,  0.1191,  0.1520],\n",
       "          [ 0.2187,  0.2133,  0.0981],\n",
       "          [ 0.2259,  0.1978,  0.1129],\n",
       "          ...,\n",
       "          [-0.0032, -0.0432,  0.3502],\n",
       "          [ 0.0102, -0.0521,  0.3527],\n",
       "          [-0.0043, -0.0646,  0.3694]],\n",
       " \n",
       "         [[ 0.2719,  0.1191,  0.1520],\n",
       "          [ 0.2187,  0.2133,  0.0981],\n",
       "          [ 0.2259,  0.1978,  0.1129],\n",
       "          ...,\n",
       "          [-0.0032, -0.0432,  0.3502],\n",
       "          [ 0.0102, -0.0521,  0.3527],\n",
       "          [-0.0043, -0.0646,  0.3694]],\n",
       " \n",
       "         [[ 0.2719,  0.1191,  0.1520],\n",
       "          [ 0.2187,  0.2133,  0.0981],\n",
       "          [ 0.2259,  0.1978,  0.1129],\n",
       "          ...,\n",
       "          [-0.0032, -0.0432,  0.3502],\n",
       "          [ 0.0102, -0.0521,  0.3527],\n",
       "          [-0.0043, -0.0646,  0.3694]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.2719,  0.1191,  0.1520],\n",
       "          [ 0.2187,  0.2133,  0.0981],\n",
       "          [ 0.2259,  0.1978,  0.1129],\n",
       "          ...,\n",
       "          [-0.0032, -0.0432,  0.3502],\n",
       "          [ 0.0102, -0.0521,  0.3527],\n",
       "          [-0.0043, -0.0646,  0.3694]],\n",
       " \n",
       "         [[ 0.2719,  0.1191,  0.1520],\n",
       "          [ 0.2187,  0.2133,  0.0981],\n",
       "          [ 0.2259,  0.1978,  0.1129],\n",
       "          ...,\n",
       "          [-0.0032, -0.0432,  0.3502],\n",
       "          [ 0.0102, -0.0521,  0.3527],\n",
       "          [-0.0043, -0.0646,  0.3694]],\n",
       " \n",
       "         [[ 0.2719,  0.1191,  0.1520],\n",
       "          [ 0.2187,  0.2133,  0.0981],\n",
       "          [ 0.2259,  0.1978,  0.1129],\n",
       "          ...,\n",
       "          [-0.0032, -0.0432,  0.3502],\n",
       "          [ 0.0102, -0.0521,  0.3527],\n",
       "          [-0.0043, -0.0646,  0.3694]]])]"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "a = next(iter(dataloader))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "0f37276c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=128x128 at 0x152A14050>"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis_tool = VisualUtil(opt.dataset)\n",
    "img = a[0][0].detach().cpu().numpy()\n",
    "jt_uvd_gt = (a[0][2] + 1) * opt.img_size / 2\n",
    "vis_tool.plot(img[0], os.path.join(awr_dir, 'sample.png'), jt_uvd_gt, jt_uvd_gt)\n",
    "\n",
    "Image.open(os.path.join(awr_dir, 'sample.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "abda38a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'K': tensor([[[266.5000,   0.0000, 160.0000],\n",
      "         [  0.0000, 266.5000, 160.0000],\n",
      "         [  0.0000,   0.0000,   1.0000]],\n",
      "\n",
      "        [[266.5000,   0.0000, 160.0000],\n",
      "         [  0.0000, 266.5000, 160.0000],\n",
      "         [  0.0000,   0.0000,   1.0000]],\n",
      "\n",
      "        [[266.5000,   0.0000, 160.0000],\n",
      "         [  0.0000, 266.5000, 160.0000],\n",
      "         [  0.0000,   0.0000,   1.0000]],\n",
      "\n",
      "        [[266.5000,   0.0000, 160.0000],\n",
      "         [  0.0000, 266.5000, 160.0000],\n",
      "         [  0.0000,   0.0000,   1.0000]],\n",
      "\n",
      "        [[266.5000,   0.0000, 160.0000],\n",
      "         [  0.0000, 266.5000, 160.0000],\n",
      "         [  0.0000,   0.0000,   1.0000]],\n",
      "\n",
      "        [[266.5000,   0.0000, 160.0000],\n",
      "         [  0.0000, 266.5000, 160.0000],\n",
      "         [  0.0000,   0.0000,   1.0000]],\n",
      "\n",
      "        [[266.5000,   0.0000, 160.0000],\n",
      "         [  0.0000, 266.5000, 160.0000],\n",
      "         [  0.0000,   0.0000,   1.0000]],\n",
      "\n",
      "        [[266.5000,   0.0000, 160.0000],\n",
      "         [  0.0000, 266.5000, 160.0000],\n",
      "         [  0.0000,   0.0000,   1.0000]],\n",
      "\n",
      "        [[266.5000,   0.0000, 160.0000],\n",
      "         [  0.0000, 266.5000, 160.0000],\n",
      "         [  0.0000,   0.0000,   1.0000]],\n",
      "\n",
      "        [[266.5000,   0.0000, 160.0000],\n",
      "         [  0.0000, 266.5000, 160.0000],\n",
      "         [  0.0000,   0.0000,   1.0000]]]), 'xyz': tensor([[[ 0.2719,  0.1191,  0.1520],\n",
      "         [ 0.2187,  0.2133,  0.0981],\n",
      "         [ 0.2259,  0.1978,  0.1129],\n",
      "         ...,\n",
      "         [-0.0032, -0.0432,  0.3502],\n",
      "         [ 0.0102, -0.0521,  0.3527],\n",
      "         [-0.0043, -0.0646,  0.3694]],\n",
      "\n",
      "        [[ 0.2719,  0.1191,  0.1520],\n",
      "         [ 0.2187,  0.2133,  0.0981],\n",
      "         [ 0.2259,  0.1978,  0.1129],\n",
      "         ...,\n",
      "         [-0.0032, -0.0432,  0.3502],\n",
      "         [ 0.0102, -0.0521,  0.3527],\n",
      "         [-0.0043, -0.0646,  0.3694]],\n",
      "\n",
      "        [[ 0.2719,  0.1191,  0.1520],\n",
      "         [ 0.2187,  0.2133,  0.0981],\n",
      "         [ 0.2259,  0.1978,  0.1129],\n",
      "         ...,\n",
      "         [-0.0032, -0.0432,  0.3502],\n",
      "         [ 0.0102, -0.0521,  0.3527],\n",
      "         [-0.0043, -0.0646,  0.3694]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.2719,  0.1191,  0.1520],\n",
      "         [ 0.2187,  0.2133,  0.0981],\n",
      "         [ 0.2259,  0.1978,  0.1129],\n",
      "         ...,\n",
      "         [-0.0032, -0.0432,  0.3502],\n",
      "         [ 0.0102, -0.0521,  0.3527],\n",
      "         [-0.0043, -0.0646,  0.3694]],\n",
      "\n",
      "        [[ 0.2719,  0.1191,  0.1520],\n",
      "         [ 0.2187,  0.2133,  0.0981],\n",
      "         [ 0.2259,  0.1978,  0.1129],\n",
      "         ...,\n",
      "         [-0.0032, -0.0432,  0.3502],\n",
      "         [ 0.0102, -0.0521,  0.3527],\n",
      "         [-0.0043, -0.0646,  0.3694]],\n",
      "\n",
      "        [[ 0.2719,  0.1191,  0.1520],\n",
      "         [ 0.2187,  0.2133,  0.0981],\n",
      "         [ 0.2259,  0.1978,  0.1129],\n",
      "         ...,\n",
      "         [-0.0032, -0.0432,  0.3502],\n",
      "         [ 0.0102, -0.0521,  0.3527],\n",
      "         [-0.0043, -0.0646,  0.3694]]]), 'uv_vis': tensor([[[636.7000, 368.9000,   0.0000],\n",
      "         [754.3000, 739.5000,   0.0000],\n",
      "         [693.3000, 627.1000,   0.0000],\n",
      "         ...,\n",
      "         [157.6000, 127.1000,   1.0000],\n",
      "         [167.7000, 120.6000,   1.0000],\n",
      "         [156.9000, 113.4000,   1.0000]],\n",
      "\n",
      "        [[636.7000, 368.9000,   0.0000],\n",
      "         [754.3000, 739.5000,   0.0000],\n",
      "         [693.3000, 627.1000,   0.0000],\n",
      "         ...,\n",
      "         [157.6000, 127.1000,   1.0000],\n",
      "         [167.7000, 120.6000,   1.0000],\n",
      "         [156.9000, 113.4000,   1.0000]],\n",
      "\n",
      "        [[636.7000, 368.9000,   0.0000],\n",
      "         [754.3000, 739.5000,   0.0000],\n",
      "         [693.3000, 627.1000,   0.0000],\n",
      "         ...,\n",
      "         [157.6000, 127.1000,   1.0000],\n",
      "         [167.7000, 120.6000,   1.0000],\n",
      "         [156.9000, 113.4000,   1.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[636.7000, 368.9000,   0.0000],\n",
      "         [754.3000, 739.5000,   0.0000],\n",
      "         [693.3000, 627.1000,   0.0000],\n",
      "         ...,\n",
      "         [157.6000, 127.1000,   1.0000],\n",
      "         [167.7000, 120.6000,   1.0000],\n",
      "         [156.9000, 113.4000,   1.0000]],\n",
      "\n",
      "        [[636.7000, 368.9000,   0.0000],\n",
      "         [754.3000, 739.5000,   0.0000],\n",
      "         [693.3000, 627.1000,   0.0000],\n",
      "         ...,\n",
      "         [157.6000, 127.1000,   1.0000],\n",
      "         [167.7000, 120.6000,   1.0000],\n",
      "         [156.9000, 113.4000,   1.0000]],\n",
      "\n",
      "        [[636.7000, 368.9000,   0.0000],\n",
      "         [754.3000, 739.5000,   0.0000],\n",
      "         [693.3000, 627.1000,   0.0000],\n",
      "         ...,\n",
      "         [157.6000, 127.1000,   1.0000],\n",
      "         [167.7000, 120.6000,   1.0000],\n",
      "         [156.9000, 113.4000,   1.0000]]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/debabratamandal/Jun-Dec 2021/rnd/ganed/lib/python3.7/site-packages/ipykernel_launcher.py:7: MatplotlibDeprecationWarning: Passing non-integers as three-element position specification is deprecated since 3.3 and will be removed two minor releases later.\n",
      "  import sys\n",
      "/Users/debabratamandal/Jun-Dec 2021/rnd/ganed/lib/python3.7/site-packages/ipykernel_launcher.py:8: MatplotlibDeprecationWarning: Passing non-integers as three-element position specification is deprecated since 3.3 and will be removed two minor releases later.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def view_samples(image, kp_coord_uv, kp_coord_uv_proj, kp_visible):\n",
    "    fig = plt.figure(1)\n",
    "    kp_coord_uv_proj = kp_coord_uv_proj\n",
    "    kp_coord_uv = kp_coord_uv\n",
    "#     print(kp_coord_uv, kp_coord_uv_proj, kp_visible)\n",
    "    kp_visible = kp_visible.numpy().astype(bool)\n",
    "    ax1 = fig.add_subplot('121')\n",
    "    ax2 = fig.add_subplot('122')\n",
    "\n",
    "    ax1.imshow(image)\n",
    "    ax2.imshow(image)\n",
    "    ax2.plot(kp_coord_uv[kp_visible, 0], kp_coord_uv[kp_visible, 1], 'ro')\n",
    "    ax2.plot(kp_coord_uv_proj[kp_visible, 0], kp_coord_uv_proj[kp_visible, 1], 'yx')\n",
    "        \n",
    "\n",
    "    plt.show()\n",
    "# a = next(iter(dataloader))\n",
    "frame = a[2][0][0][0]\n",
    "print(a[2][1])\n",
    "kp_coord_xyz, kp_coord_uv, kp_visible, kp_coord_uv_proj = generate_gt_B(a[2][1])\n",
    "view_samples(frame, kp_coord_uv[0], kp_coord_uv_proj[0], kp_visible[0])\n",
    "# cv2.imwrite(os.path.join(handtailor_dir, \"sample_image.png\"), np.flip(frame.numpy(),-1))\n",
    "# Image.open(os.path.join(handtailor_dir, 'sample_image.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "5e3c2096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0187, grad_fn=<DivBackward0>)\n",
      "Latent dimension A:  torch.Size([10, 56, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "# Tests A\n",
    "A = a[0]\n",
    "x, *out = base_awr_encoder(*A)\n",
    "offset_pred, jt_uvd_pred = awr_decoder(x, *out)\n",
    "\n",
    "img = A[0].detach().cpu().numpy()\n",
    "jt_uvd_gt = (A[2] + 1) * opt.img_size / 2\n",
    "jt_uvd_pred = (jt_uvd_pred + 1) * opt.img_size / 2\n",
    "\n",
    "print(torch.max(jt_uvd_gt-jt_uvd_pred)/torch.max(jt_uvd_gt))\n",
    "print(\"Latent dimension A: \", x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "58a0127b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latent dimension B:  torch.Size([10, 256, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "# Tests B\n",
    "B = a[2][0]\n",
    "out = base_ht_encoder(*B)\n",
    "print(\"Latent dimension B: \", out[0][1][-1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "a910e754",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = ht_decoder1(*out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "2b2caf0e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "add got incompatible shapes for broadcasting: (10, 21, 2), (10, 21, 4).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/h5/g2hdccgs6xb4yzc58gvby2y80000gn/T/ipykernel_32647/348115466.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mface\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'f'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mht_p3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/h5/g2hdccgs6xb4yzc58gvby2y80000gn/T/ipykernel_32647/564672155.py\u001b[0m in \u001b[0;36mht_p3\u001b[0;34m(joint, hm, camparam, bone, joint_root, so3, beta, frame, intr)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mso3_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mjoint_root\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkp2d\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcamparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mopt_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "    \u001b[0;31m[... skipping hidden 38 frame]\u001b[0m\n",
      "\u001b[0;32m~/Jun-Dec 2021/rnd/exp/HandTailor/demo_in_the_wild.py\u001b[0m in \u001b[0;36mresiduals\u001b[0;34m(input_list, so3_init, beta_init, kp2d, s, t)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mgeo_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoint_mano\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0mxy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoint_mano\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0muv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mxy\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m     \u001b[0merrkp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muv\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mkp2d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mreg_beta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0merrkp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgeo_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/Jun-Dec 2021/rnd/ganed/lib/python3.7/site-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36mdeferring_binary_op\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   6015\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_scalar_types\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0m_arraylike_types\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTracer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6016\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6017\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6018\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdeferring_binary_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6019\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "    \u001b[0;31m[... skipping hidden 17 frame]\u001b[0m\n",
      "\u001b[0;32m~/Jun-Dec 2021/rnd/ganed/lib/python3.7/site-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(x1, x2)\u001b[0m\n\u001b[1;32m    434\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_promote_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlax_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mbool_\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mbool_lax_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m   \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlax_doc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "    \u001b[0;31m[... skipping hidden 11 frame]\u001b[0m\n",
      "\u001b[0;32m~/Jun-Dec 2021/rnd/ganed/lib/python3.7/site-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36m_broadcasting_shape_rule\u001b[0;34m(name, *avals)\u001b[0m\n\u001b[1;32m   2243\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mresult_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2244\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{} got incompatible shapes for broadcasting: {}.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2245\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2246\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: add got incompatible shapes for broadcasting: (10, 21, 2), (10, 21, 4)."
     ]
    }
   ],
   "source": [
    "\n",
    "from HandTailor.utils import MeshRenderer, OpendrRenderer\n",
    "\n",
    "dd = pickle.load(open(os.path.join(file_dir, \"MANO_RIGHT.pkl\"), 'rb'), encoding='latin1')\n",
    "face = np.array(dd['f'])\n",
    "\n",
    "v, intr, frame = ht_p3(*out)\n",
    "v = np.array(v)\n",
    "print(v)\n",
    "intr = intr[0].cpu()\n",
    "frame = frame.numpy()[0]\n",
    "print(v, intr)\n",
    "# intr[2, 2] = -1\n",
    "\n",
    "print(frame.shape, np.flip(frame, axis=0).shape)\n",
    "# v = np.load(\"./some.npy\")\n",
    "if ARGS.HandTailor['wild']:\n",
    "    renderer = OpendrRenderer(img_size=256)\n",
    "    frame1 = renderer.render(v.copy(),face,frame)\n",
    "else:\n",
    "    renderer = MeshRenderer(face, img_size=256)\n",
    "    frame1 = renderer(v, intr, frame)\n",
    "cv2.imwrite(os.path.join(handtailor_dir, 'sample.png'), np.flip(frame1,-1))\n",
    "Image.open(os.path.join(handtailor_dir, 'sample.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afefdd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "numc_awr = 56\n",
    "numc_ht = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "555d15a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x1553b6d10>"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bf809c",
   "metadata": {},
   "source": [
    "### CycleGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf9d166",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(in_features, in_features, 3),\n",
    "            nn.InstanceNorm2d(in_features),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(in_features, in_features, 3),\n",
    "            nn.InstanceNorm2d(in_features),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.conv_block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6ee6eec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGANGenerator(nn.Module):\n",
    "    def __init__(self, image_batch, in_channels=3, out_channels=3, res_blocks=5):\n",
    "        super(CycleGANGenerator, self).__init__()\n",
    "        self.encoding_dims = in_channels\n",
    "\n",
    "        self.image_batch = image_batch\n",
    "\n",
    "        # Initial convolution block\n",
    "        model = [\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(in_channels, 64, 7),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "        ]\n",
    "\n",
    "        # Downsampling\n",
    "        in_features = 64\n",
    "        out_features = in_features * 2\n",
    "        for _ in range(2):\n",
    "            model += [\n",
    "                nn.Conv2d(in_features, out_features, 4, stride=2, padding=1),\n",
    "                nn.InstanceNorm2d(out_features),\n",
    "                nn.ReLU(inplace=True),\n",
    "            ]\n",
    "            in_features = out_features\n",
    "            out_features = in_features * 2\n",
    "\n",
    "        # Residual blocks\n",
    "        for _ in range(res_blocks):\n",
    "            model += [ResidualBlock(in_features)]\n",
    "\n",
    "        # Upsampling\n",
    "        out_features = in_features // 2\n",
    "        for _ in range(2):\n",
    "            model += [\n",
    "                nn.ConvTranspose2d(in_features, out_features, 4, stride=2, padding=1),\n",
    "                nn.InstanceNorm2d(out_features),\n",
    "                nn.ReLU(inplace=True),\n",
    "            ]\n",
    "            in_features = out_features\n",
    "            out_features = in_features // 2\n",
    "\n",
    "        # Output layer\n",
    "        model += [nn.ReflectionPad2d(3), nn.Conv2d(64, out_channels, 7), nn.Tanh()]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "        self._weight_initializer()\n",
    "\n",
    "    def _weight_initializer(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.ConvTranspose2d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1.0)\n",
    "                nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "gan_a2b = CycleGANGenerator(BATCH_SIZE, numc_awr, numc_ht)\n",
    "gan_b2a = CycleGANGenerator(BATCH_SIZE, numc_ht, numc_awr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c0b01e1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 56, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "A, gt_A, B, gt_B = a\n",
    "lat_A, *others_A = awr_p1(*A)\n",
    "lat_B, *others_B = ht_p1(*B[0])\n",
    "print(lat_A.shape)\n",
    "assert( gan_a2b(lat_A).shape == lat_B[1][-1].shape )\n",
    "assert( gan_b2a(lat_B[1][-1]).shape == lat_A.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6c6b7ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGANDiscriminator(nn.Module):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super(CycleGANDiscriminator, self).__init__()\n",
    "        \n",
    "        def discriminator_block(in_filters, out_filters, normalize=True):\n",
    "            layers = [nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1)]\n",
    "            if normalize:\n",
    "                layers.append(nn.InstanceNorm2d(out_filters))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *discriminator_block(in_channels, 64, normalize=False),\n",
    "            *discriminator_block(64, 128),\n",
    "            *discriminator_block(128, 256),\n",
    "            *discriminator_block(256, 512),\n",
    "            nn.ZeroPad2d((1, 0, 1, 0)),\n",
    "            nn.Conv2d(512, 1, 4, padding=1)\n",
    "        )\n",
    "\n",
    "        self._weight_initializer()\n",
    "\n",
    "    def _weight_initializer(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1.0)\n",
    "                nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "disc_a = CycleGANDiscriminator(numc_awr)\n",
    "disc_b = CycleGANDiscriminator(numc_ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "38a40b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 4, 4]) torch.Size([10, 1, 4, 4])\n",
      "tensor([[[-0.3731,  1.2385, -0.3582,  0.0235],\n",
      "         [-0.5214, -0.9241,  0.5709, -0.6839],\n",
      "         [ 0.5917,  0.6004,  0.7242,  1.1733],\n",
      "         [-1.1386, -0.1705,  0.6121,  0.4047]]], grad_fn=<SelectBackward>) tensor([[[-0.4907, -0.5998,  1.2401,  0.0273],\n",
      "         [-0.1833, -0.8928, -0.6193, -1.1531],\n",
      "         [ 0.6935, -0.8414, -1.4833, -0.5691],\n",
      "         [ 0.9519, -0.6688, -0.1537,  0.3295]]], grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "x = disc_b(gan_a2b(lat_A))\n",
    "y = disc_a(gan_b2a(lat_B[1][-1]))\n",
    "print(x.shape, y.shape)\n",
    "print(x[0], y[0])\n",
    "# print(x.isnan(), lat_A.isnan(), y.isnan())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e39ad2c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4c514e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2819009 8190848\n"
     ]
    }
   ],
   "source": [
    "\n",
    "optim_disc_a = optim.Adam(disc_a.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
    "optim_disc_b = optim.Adam(disc_b.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
    "optim_gan_a2b = optim.Adam(gan_a2b.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
    "optim_gan_b2a = optim.Adam(gan_b2a.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
    "\n",
    "# optim_awr = optim.Adam(awr_p1.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
    "# optim_ht = optim.Adam(ht_p1.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
    "\n",
    "\n",
    "a = sum(p.numel() for p in disc_a.parameters())\n",
    "b = sum(p.numel() for p in disc_b.parameters())\n",
    "c = sum(p.numel() for p in gan_a2b.parameters())\n",
    "d = sum(p.numel() for p in gan_b2a.parameters())\n",
    "\n",
    "print(a, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a40f112e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CycleGANGeneratorLoss(\n",
    "        gen_a2b,\n",
    "        gen_b2a,\n",
    "        dis_a,\n",
    "        dis_b,\n",
    "        optimizer_gen_a2b,\n",
    "        optimizer_gen_b2a,\n",
    "        image_a,\n",
    "        image_b,\n",
    "    ):\n",
    "        optimizer_gen_a2b.zero_grad()\n",
    "        optimizer_gen_b2a.zero_grad()\n",
    "        fake_a = gen_b2a(image_b)\n",
    "        fake_b = gen_a2b(image_a)\n",
    "        loss_identity_a2b = 0.5 * F.l1_loss(fake_b, image_b)\n",
    "        loss_identity_b2a = 0.5 * F.l1_loss(fake_a, image_a)\n",
    "#         loss_identity = 0.5 * (F.l1_loss(fake_a, image_a) + F.l1_loss(fake_b, image_b))\n",
    "        loss_gan_a2b = 0.5 * least_squares_generator_loss(dis_b(fake_b))\n",
    "        loss_gan_b2a = 0.5 * least_squares_generator_loss(dis_a(fake_a))\n",
    "#         loss_gan = 0.5 * (\n",
    "#             least_squares_generator_loss(dis_a(fake_a))\n",
    "#             + least_squares_generator_loss(dis_b(fake_b))\n",
    "#         )\n",
    "        loss_cycle_consistency = 0.5 * (\n",
    "            F.l1_loss(gen_a2b(fake_a), image_b) + F.l1_loss(gen_b2a(fake_b), image_a)\n",
    "        )\n",
    "#         loss = loss_identity + loss_gan + loss_cycle_consistency\n",
    "        loss = loss_identity_a2b + loss_identity_b2a + loss_gan_a2b + loss_gan_b2a + loss_cycle_consistency\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer_gen_a2b.step()\n",
    "        optimizer_gen_b2a.step()\n",
    "        return loss.item(), loss_identity_a2b.item(), loss_identity_b2a.item(), loss_gan_a2b.item(), loss_gan_b2a.item(), loss_cycle_consistency.item()\n",
    "\n",
    "loss = CycleGANGeneratorLoss(gan_a2b, gan_b2a, disc_a, disc_b, optim_gan_a2b, optim_gan_b2a, lat_A, lat_B[1][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a4d88079",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CycleGANDiscriminatorLoss(\n",
    "        gen_a2b,\n",
    "        gen_b2a,\n",
    "        dis_a,\n",
    "        dis_b,\n",
    "        optimizer_dis_a,\n",
    "        optimizer_dis_b,\n",
    "        image_a,\n",
    "        image_b,\n",
    "    ):\n",
    "        optimizer_dis_a.zero_grad()\n",
    "        optimizer_dis_b.zero_grad()\n",
    "        fake_a = gen_b2a(image_b).detach()\n",
    "        fake_b = gen_a2b(image_a).detach()\n",
    "        loss_b2a = 0.5 * least_squares_discriminator_loss(dis_a(image_a), dis_a(fake_a))\n",
    "        loss_a2b = 0.5 * least_squares_discriminator_loss(dis_b(image_b), dis_b(fake_b))\n",
    "#         loss = 0.5 * (\n",
    "#             least_squares_discriminator_loss(dis_a(image_a), dis_a(fake_a))\n",
    "#             + least_squares_discriminator_loss(dis_b(image_b), dis_b(fake_b))\n",
    "#         )\n",
    "        loss = loss_a2b + loss_b2a\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer_dis_a.step()\n",
    "        optimizer_dis_b.step()\n",
    "        return loss.item(), loss_a2b.item(), loss_b2a.item()\n",
    "    \n",
    "loss = CycleGANDiscriminatorLoss(gan_a2b, gan_b2a, disc_a, disc_b, optim_disc_a, optim_disc_b, lat_A, lat_B[1][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "37048bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(prediction, target):\n",
    "    loss_fn = nn.MSELoss()\n",
    "    RMSE_loss = torch.sqrt(loss_fn(prediction, target))\n",
    "#     RMSE_loss.backward(retain_graph=True)\n",
    "\n",
    "    return RMSE_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c0e0ffd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a -> AWR (Depth), b -> Handtailor (RGB)\n",
    "\n",
    "def train_step(A, gt_A, B, gt_B):\n",
    "# a = A, gt_A, B, gt_B\n",
    "    lat_A, *others_A = awr_p1(*A)\n",
    "    lat_B, *others_B = ht_p1(*B[0])\n",
    "\n",
    "    _, out_A = awr_p2(lat_A, *others_A)\n",
    "    *_, _gt_jt_root, _gt_so3, _gt_beta, _, _ = ht_p2(lat_B, *others_B)\n",
    "\n",
    "    gan_loss = CycleGANGeneratorLoss(gan_a2b, gan_b2a, disc_a, disc_b, optim_gan_a2b, optim_gan_b2a, lat_A, lat_B[1][-1])\n",
    "    disc_loss = CycleGANDiscriminatorLoss(gan_a2b, gan_b2a, disc_a, disc_b, optim_disc_a, optim_disc_b, lat_A, lat_B[1][-1])\n",
    "\n",
    "#     optim_awr.zero_grad()\n",
    "#     optim_ht.zero_grad()\n",
    "    \n",
    "    #Calculate metrics\n",
    "    # print(_gt_so3, gt_B)\n",
    "#     awr_loss = RMSE(out_A, gt_A)\n",
    "#     ht_loss = RMSE(_gt_beta, gt_B)\n",
    "\n",
    "#     optim_awr.step()\n",
    "#     optim_ht.step()\n",
    "\n",
    "#     return {\"GAN Loss\": gan_loss, \"Discriminator loss\": disc_loss, \"AWR loss\": awr_loss, \"HT loss\": ht_loss}\n",
    "    return {\"GAN Loss\": gan_loss[0], \"Discriminator loss\": disc_loss[0]}, gan_loss, disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "62fc1115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x183301b50>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "14003e30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 99\n",
      "1 99\n",
      "2 99\n",
      "3 99\n",
      "4 99\n",
      "5 99\n",
      "6 99\n",
      "7 99\n",
      "8 99\n",
      "9 99\n",
      "{'GAN Loss': 2.2462985515594482, 'Discriminator loss': 3.0547869205474854}\n",
      "10 99\n",
      "11 99\n",
      "12 99\n",
      "13 99\n",
      "14 99\n",
      "15 99\n",
      "16 99\n",
      "17 99\n",
      "18 99\n",
      "19 99\n",
      "{'GAN Loss': 1.865211009979248, 'Discriminator loss': 2.183131217956543}\n",
      "20 99\n",
      "21 99\n",
      "22 99\n",
      "23 99\n",
      "24 99\n",
      "25 99\n",
      "26 99\n",
      "27 99\n",
      "28 99\n",
      "29 99\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/h5/g2hdccgs6xb4yzc58gvby2y80000gn/T/ipykernel_74475/3240548994.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mgan_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mdisc_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/h5/g2hdccgs6xb4yzc58gvby2y80000gn/T/ipykernel_74475/3407348179.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(A, gt_A, B, gt_B)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;34m*\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_gt_jt_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_gt_so3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_gt_beta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mht_p2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlat_B\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mothers_B\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mgan_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCycleGANGeneratorLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgan_a2b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgan_b2a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisc_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisc_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim_gan_a2b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim_gan_b2a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlat_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlat_B\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mdisc_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCycleGANDiscriminatorLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgan_a2b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgan_b2a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisc_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisc_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim_disc_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim_disc_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlat_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlat_B\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/h5/g2hdccgs6xb4yzc58gvby2y80000gn/T/ipykernel_74475/737474037.py\u001b[0m in \u001b[0;36mCycleGANGeneratorLoss\u001b[0;34m(gen_a2b, gen_b2a, dis_a, dis_b, optimizer_gen_a2b, optimizer_gen_b2a, image_a, image_b)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m#         loss = loss_identity + loss_gan + loss_cycle_consistency\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_identity_a2b\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_identity_b2a\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_gan_a2b\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_gan_b2a\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_cycle_consistency\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0moptimizer_gen_a2b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0moptimizer_gen_b2a\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Jun-Dec 2021/rnd/ganed/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Jun-Dec 2021/rnd/ganed/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gan_losses = []\n",
    "disc_losses = []\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    n = 0\n",
    "    for data in dataloader:\n",
    "        loss = train_step(*data)\n",
    "        gan_losses.append(loss[1])\n",
    "        disc_losses.append(loss[2])\n",
    "        print(loss[0])\n",
    "#         if n % 10 == 0:\n",
    "#             print ('.', end='')\n",
    "#         n += 1\n",
    "#         break\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print ('Time taken for epoch {} is {} sec\\n'.format(epoch + 1, time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8a330d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a - Depth, b - RGB\n",
    "# loss_identity_a2b, loss_identity_b2a, loss_gan_a2b, loss_gan_b2a, loss_cycle_consistency\n",
    "# Epoch 1\n",
    "print(gan_losses[0][1:])\n",
    "# Epoch 500\n",
    "print(gan_losses[-1][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72449539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a - Depth, b - RGB\n",
    "# loss_a2b, loss_b2a\n",
    "# Epoch 1\n",
    "print(disc_losses[0][1:])\n",
    "# Epoch 500\n",
    "print(disc_losses[-1][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faccac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in dataloader:\n",
    "    a = data[0]\n",
    "#     print(len(a))\n",
    "    out = gan_a2b(awr_p1(*data[0])[0]).detach().numpy()\n",
    "    bre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855559c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159de700",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
